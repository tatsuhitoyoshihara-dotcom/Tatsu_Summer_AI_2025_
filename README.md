# Tatsu_Summer_AI_2025_

Pococha, Twitch, そしてYoutubeの分析に使ったファイルをgithubに載せました。
時間の制約上、それぞれ扱ったデータ量、そして収集したデータ量は小規模になります。特にTwitchは10のworker.ipynbを並列で動かすため頻繁にkernelが落ちてしまい、他の作業を優先するためデータ収集期間は3日間でした。また、YouTubeはbot対策のため、これまた20分ごとにcookieを発行して絶対パスを貼り換え続けるという作業が必要であるため、一回のみ、200件弱のみを収集しました。なお、YouTubeには研究者用のAPIがあり、それ以外の非公式のツールでデータをダウンロードを収集することを禁じていますので、今回のコードの内容も、規約違反であるという認識です。
今回githubに載せたコードは、完璧なコードではなく、エラーに対処しながら、つぎはぎしながら動かしたコードですので、1. kernel落ち耐性をつける、2. 綺麗にデータを整理する、3. データをもっと大規模に収集する場合には、githubのコードをLLMに読み込ませ、これを土台としながら新しくコードを作成する必要があると考えます。

完璧とは程遠いコードをお渡しすることになったこと、申し訳ありません。
私のコーディングスキルが欠落しており、LLMに大きく頼ってコードを書いた結果です。


このコードを動かすためには、twitchとyoutubeの両方において、APIのkeyを取得する必要があります。課金要素は一切ありません。また、cookieも取得する必要があります。私は、新しいクリーンなgoogle accountを作成し（保証用のメルアドには個人的なアドレスを入力）、そしてgoogle chromeでGet cookies.txt LOCALLYの拡張機能を用いてcookieを取得していました。
なおYouTubeのコードを動かすのは、DeNAさんのパソコンでは（youtubeにアクセスが）出来ないため）困難であると考えています。そのため私用のパソコンを使うことを想定しています。
そのためには、ディスクの容量を200GBほど空けておく必要があると思います（約200件のライブ配信でaudio+comment=40GBほど、5回収拾で200GB）。
そのデータをgdriveに入れて、会社のパソコンに転送します。

今回のコードではYouTubeとTwitchの書き起こしで、Open AI Whisper(base model)を使いました。LLM QAの(コメントのみを読んだLLMによる)最終的な正答率は、この音声データの書き起こし精度に大きく依存すると考えています。Pocochaの音声テキストはノイズが小さくなく、それゆえに問題を生成するとき、コメントの内容のみを読んで答えられる問題が増えたものと認識しております。もし音声の書き起こし精度が高い場合、我々の結果の8-9割の精度は、もっと落ちるものと考えます。当然、正答率は、コメントと音声書き起こしのテキスト量の比率にも依存すると思います。（安達さんから頂いた）Pocochaの書き起こしですが、Open AI Whipserを使っている場合には、もう一段階高いレベルのモデルを使用することを検討しても良いと考えました。

