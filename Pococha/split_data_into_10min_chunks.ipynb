{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMC7AiEjGPxxvCrMzNBz1Kw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wsTuyPrmpQmu"},"outputs":[],"source":["# ============================================\n","# Chunked text exporter (CHAT+SPEECH / CHAT-only)\n","# - 時間表記はテキストに含めない（[SOURCE] 本文 のみ）\n","# - 10分チャンクで分割し、GCSへ逐次アップロード\n","# - 進捗バー表示、再実行時は既存ファイルを検出してスキップ（レジューム対応）\n","# ============================================\n","\n","from __future__ import annotations\n","import os\n","import re\n","from typing import List, Dict, Optional, Iterable, Tuple\n","\n","import pandas as pd\n","from tqdm.auto import tqdm\n","\n","# GCS\n","import gcsfs\n","\n","# -----------------------\n","# 設定\n","# -----------------------\n","# GCS 上の入力ディレクトリ（コメントCSVが大量にある場所）\n","COMMENT_DIR_GCS = \"gs://dena-ai-intern-yoshihara-data/pococha_comment_sorted\"\n","\n","# 全 live_id を俯瞰できる “一覧CSV” がローカルにある場合は指定（なければ自動でGCS列挙）\n","# 例: 前段のリストアップ処理で作った pococha_comment_sorted_suffixes.csv\n","LOCAL_LISTING_CSV = \"pococha_comment_sorted_suffixes.csv\"  # 無ければ自動列挙にフォールバック\n","\n","# 音声（文字起こし）全集（live_id混在）CSVのGCSパス\n","AUDIO_GCS_PATH = \"gs://dena-ai-intern-yoshihara-data/pococha_speech/bq-results-20250903-061249-1756880068827.csv\"\n","\n","# 出力先（拡張子は .txt を採用）\n","OUT_COMBINED_PREFIX = \"gs://dena-ai-intern-yoshihara-data/yoshi_LLMQA_comment_speeech_combined\"  # ←speeech（eが3つ）仕様\n","OUT_CHATONLY_PREFIX = \"gs://dena-ai-intern-yoshihara-data/yoshi_LLMQA_comment_only\"\n","OUT_EXT = \".txt\"\n","\n","# 10分 = 600秒 チャンク\n","CHUNK_SECONDS = 600\n","\n","# 例外が出た live_id を記録して最後に表示する\n","ERROR_LOG: List[Tuple[int, str]] = []\n","\n","# --------------------------------\n","# ユーティリティ\n","# --------------------------------\n","def parse_live_id_from_comment_path(path: str) -> Optional[int]:\n","    \"\"\"\n","    パス末尾の comment_68412208.csv から live_id を抽出\n","    \"\"\"\n","    base = os.path.basename(path)\n","    m = re.search(r\"comment_(\\d+)\\.csv$\", base)\n","    return int(m.group(1)) if m else None\n","\n","\n","def to_int_seconds_safe(x) -> int:\n","    \"\"\"\n","    秒の列を安全にint化（NaN→0、負値→0）\n","    \"\"\"\n","    v = pd.to_numeric(x, errors=\"coerce\")\n","    v = 0 if pd.isna(v) else int(v)\n","    return max(0, v)\n","\n","\n","def list_comment_files(fs: gcsfs.GCSFileSystem, comment_dir_gcs: str, local_listing_csv: Optional[str]) -> List[str]:\n","    \"\"\"\n","    コメントCSV（comment_*.csv）のGCSパスを列挙。\n","    可能ならローカルの一覧CSV（suffix_number付き）を使い、なければgcsfsで列挙。\n","    \"\"\"\n","    if local_listing_csv and os.path.exists(local_listing_csv):\n","        df = pd.read_csv(local_listing_csv)\n","        if \"gcs_path\" in df.columns:\n","            files = df[\"gcs_path\"].dropna().astype(str).tolist()\n","            # 念のためフィルタ\n","            files = [p for p in files if p.startswith(comment_dir_gcs) and p.endswith(\".csv\")]\n","            return files\n","\n","    # Fallback: GCSを直接列挙\n","    pattern = comment_dir_gcs.rstrip(\"/\") + \"/comment_*.csv\"\n","    return fs.glob(pattern)\n","\n","\n","def read_comments_one_live(fs: gcsfs.GCSFileSystem, comment_csv_gcs: str) -> pd.DataFrame:\n","    \"\"\"\n","    単一 live_id のコメントCSVを読み、必要列があるかバリデート。\n","    必須列: ['live_id','user_id','text','comment_time','live_started_time','elapsed_seconds']\n","    \"\"\"\n","    df = pd.read_csv(comment_csv_gcs)\n","    required = ['live_id', 'user_id', 'text', 'comment_time', 'live_started_time', 'elapsed_seconds']\n","    missing = [c for c in required if c not in df.columns]\n","    if missing:\n","        raise ValueError(f\"コメントCSVに必要な列が不足: {missing} @ {comment_csv_gcs}\")\n","    # 整形\n","    out = df.copy()\n","    out[\"t\"] = [to_int_seconds_safe(x) for x in out[\"elapsed_seconds\"]]\n","    out[\"source\"] = \"CHAT\"\n","    out[\"content\"] = out[\"text\"].astype(str).fillna(\"\").str.strip()\n","    out[\"orig_idx\"] = range(len(out))\n","    return out[[\"live_id\",\"source\",\"t\",\"content\",\"orig_idx\"]]\n","\n","\n","def read_audio_all(fs: gcsfs.GCSFileSystem, audio_csv_gcs: str) -> pd.DataFrame:\n","    \"\"\"\n","    音声（文字起こし）全集を読み込み（live_id混在）。\n","    必須列: ['live_id','audio_path','timestamp_start','timestamp_end','transcription']\n","    \"\"\"\n","    df = pd.read_csv(audio_csv_gcs)\n","    required = ['live_id', 'audio_path', 'timestamp_start', 'timestamp_end', 'transcription']\n","    missing = [c for c in required if c not in df.columns]\n","    if missing:\n","        raise ValueError(f\"音声CSVに必要な列が不足: {missing} @ {audio_csv_gcs}\")\n","\n","    # t=timestamp_start(int秒)に正規化\n","    out = df.copy()\n","    out[\"t\"] = [to_int_seconds_safe(x) for x in out[\"timestamp_start\"]]\n","    out[\"source\"] = \"SPEECH\"\n","    out[\"content\"] = out[\"transcription\"].astype(str).fillna(\"\").str.strip()\n","    out[\"orig_idx\"] = range(len(out))\n","    return out[[\"live_id\",\"source\",\"t\",\"content\",\"orig_idx\"]]\n","\n","\n","def merge_chat_speech(chat_df: pd.DataFrame, speech_df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    CHATとSPEECHを時間順にマージ（安定ソート）。\n","    タイブレーク: t昇順、CHAT先→SPEECH後、orig_idx順維持。\n","    \"\"\"\n","    # 空コンテンツ除去\n","    chat = chat_df[chat_df[\"content\"].astype(str).str.len() > 0].copy()\n","    speech = speech_df[speech_df[\"content\"].astype(str).str.len() > 0].copy()\n","\n","    merged = pd.concat([chat, speech], ignore_index=True)\n","    source_order = merged[\"source\"].map({\"CHAT\":0, \"SPEECH\":1}).fillna(2).astype(int)\n","    merged = merged.assign(_source_order=source_order)\n","    merged = merged.sort_values([\"t\",\"_source_order\",\"orig_idx\"], kind=\"mergesort\").drop(columns=[\"_source_order\"])\n","    merged = merged.reset_index(drop=True)\n","    return merged\n","\n","\n","def iter_chunk_indices(max_t: int, chunk_seconds: int = CHUNK_SECONDS) -> Iterable[int]:\n","    \"\"\"\n","    最大時刻（秒）から、1始まりのチャンク番号を列挙。\n","    例: max_t=0..599 -> 1のみ, 600..1199 -> 1,2\n","    \"\"\"\n","    if max_t < 0:\n","        return []\n","    last_chunk = (max_t // chunk_seconds) + 1 if max_t >= 0 else 1\n","    return range(1, last_chunk + 1)\n","\n","\n","def build_text_lines(df: pd.DataFrame) -> List[str]:\n","    \"\"\"\n","    行を [SOURCE] 本文 の形式にする（時間は含めない）。\n","    ※ f-string の {expr} 内にバックスラッシュを含むと SyntaxError になるので、\n","       事前にクレンジングしてから f-string で変数を埋め込む。\n","    \"\"\"\n","    if df.empty:\n","        return []\n","    lines: List[str] = []\n","    for row in df.itertuples(index=False):\n","        # 改行をスペースに、前後空白トリム\n","        text_clean = str(row.content).replace(\"\\n\", \" \").strip()\n","        line = f\"[{row.source}] {text_clean}\"\n","        lines.append(line)\n","    return lines\n","\n","\n","def write_text_gcs(fs: gcsfs.GCSFileSystem, gcs_path: str, text: str) -> None:\n","    \"\"\"\n","    GCSへUTF-8でテキスト書き込み（上書き）。\n","    \"\"\"\n","    with fs.open(gcs_path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(text if text.endswith(\"\\n\") else text + \"\\n\")\n","\n","\n","def ensure_prefix_slash_removed(prefix: str) -> str:\n","    return prefix[:-1] if prefix.endswith(\"/\") else prefix\n","\n","\n","def output_path(prefix: str, live_id: int, chunk_idx: int, ext: str = OUT_EXT) -> str:\n","    prefix = ensure_prefix_slash_removed(prefix)\n","    return f\"{prefix}/{live_id}_{chunk_idx}{ext}\"\n","\n","\n","# --------------------------------\n","# メイン処理\n","# --------------------------------\n","def main():\n","    fs = gcsfs.GCSFileSystem()\n","\n","    # 1) 対象コメントファイルの一覧を取得\n","    comment_files = list_comment_files(fs, COMMENT_DIR_GCS, LOCAL_LISTING_CSV)\n","    if not comment_files:\n","        print(\"コメントCSVが見つかりません。設定や権限を確認してください。\")\n","        return\n","\n","    # 2) 音声全集を一度だけ読み込み\n","    print(\"音声CSVを読込中...\")\n","    audio_all = read_audio_all(fs, AUDIO_GCS_PATH)\n","\n","    # live_id -> speech_df のビューをすぐ作れるように groupby\n","    audio_grouped = audio_all.groupby(\"live_id\", sort=False)\n","\n","    # 3) 進捗バー（外側：ライブ数）\n","    created_count = 0\n","    skipped_count = 0\n","\n","    # live_idを安定順で処理（path上の番号順）\n","    comment_files_sorted = sorted(comment_files, key=lambda p: parse_live_id_from_comment_path(p) or 0)\n","\n","    pbar = tqdm(comment_files_sorted, desc=\"Lives\", unit=\"live\")\n","\n","    for comment_csv in pbar:\n","        try:\n","            live_id = parse_live_id_from_comment_path(comment_csv)\n","            if live_id is None:\n","                # 形式外のファイルはスキップ\n","                continue\n","\n","            pbar.set_postfix_str(f\"live_id={live_id}\")\n","\n","            # コメント読み込み\n","            chat_df = read_comments_one_live(fs, comment_csv)\n","            # 該当liveの音声（無い可能性がある）\n","            try:\n","                speech_df = audio_grouped.get_group(live_id)[[\"live_id\",\"source\",\"t\",\"content\",\"orig_idx\"]].copy()\n","            except KeyError:\n","                speech_df = pd.DataFrame(columns=[\"live_id\",\"source\",\"t\",\"content\",\"orig_idx\"])\n","\n","            # マージ（時間順）\n","            merged = merge_chat_speech(chat_df, speech_df)\n","\n","            # チャンク番号付与（1始まり）\n","            if not merged.empty:\n","                merged[\"chunk_idx\"] = (merged[\"t\"] // CHUNK_SECONDS) + 1\n","            if not chat_df.empty:\n","                chat_df = chat_df.sort_values([\"t\",\"orig_idx\"], kind=\"mergesort\").reset_index(drop=True)\n","                chat_df[\"chunk_idx\"] = (chat_df[\"t\"] // CHUNK_SECONDS) + 1\n","\n","            # max_t を把握してチャンク列挙（両データの最大）\n","            max_t_candidates = []\n","            if not merged.empty:\n","                max_t_candidates.append(int(merged[\"t\"].max()))\n","            if not chat_df.empty:\n","                max_t_candidates.append(int(chat_df[\"t\"].max()))\n","            max_t = max(max_t_candidates) if max_t_candidates else -1\n","\n","            if max_t < 0:\n","                # 何も無ければスキップ\n","                continue\n","\n","            # 内側の進捗バー（このliveで出力する総チャンク数×2（combined/chatonly））\n","            live_chunks = list(iter_chunk_indices(max_t, CHUNK_SECONDS))\n","            inner_total = len(live_chunks) * 2  # combined + chatonly\n","            inner_bar = tqdm(total=inner_total, desc=f\"live {live_id}\", leave=False)\n","\n","            # ---- Combined（CHAT+SPEECH） ----\n","            for idx in live_chunks:\n","                out_path = output_path(OUT_COMBINED_PREFIX, live_id, idx, OUT_EXT)\n","                if fs.exists(out_path):\n","                    skipped_count += 1\n","                    inner_bar.update(1)\n","                    inner_bar.set_postfix_str(f\"combined skip {os.path.basename(out_path)}\")\n","                    continue\n","\n","                # チャンク内の行を抽出（時系列保持済み）\n","                if merged.empty:\n","                    lines = []\n","                else:\n","                    part = merged[merged[\"chunk_idx\"] == idx]\n","                    lines = build_text_lines(part)\n","\n","                # 空チャンクはスキップ（ファイルを作らない）\n","                if not lines:\n","                    inner_bar.update(1)\n","                    inner_bar.set_postfix_str(f\"combined empty chunk {idx}\")\n","                    continue\n","\n","                # 書き込み\n","                write_text_gcs(fs, out_path, \"\\n\".join(lines))\n","                created_count += 1\n","                inner_bar.update(1)\n","                inner_bar.set_postfix_str(f\"combined wrote {os.path.basename(out_path)}\")\n","\n","            # ---- Chat-only（SPEECH抜き） ----\n","            for idx in live_chunks:\n","                out_path = output_path(OUT_CHATONLY_PREFIX, live_id, idx, OUT_EXT)\n","                if fs.exists(out_path):\n","                    skipped_count += 1\n","                    inner_bar.update(1)\n","                    inner_bar.set_postfix_str(f\"chatonly skip {os.path.basename(out_path)}\")\n","                    continue\n","\n","                if chat_df.empty:\n","                    lines = []\n","                else:\n","                    part = chat_df[chat_df[\"chunk_idx\"] == idx]\n","                    lines = build_text_lines(part)  # [CHAT] 本文 形式\n","\n","                if not lines:\n","                    inner_bar.update(1)\n","                    inner_bar.set_postfix_str(f\"chatonly empty chunk {idx}\")\n","                    continue\n","\n","                write_text_gcs(fs, out_path, \"\\n\".join(lines))\n","                created_count += 1\n","                inner_bar.update(1)\n","                inner_bar.set_postfix_str(f\"chatonly wrote {os.path.basename(out_path)}\")\n","\n","            inner_bar.close()\n","\n","        except Exception as e:\n","            ERROR_LOG.append((parse_live_id_from_comment_path(comment_csv) or -1, str(e)))\n","            # エラーでも他liveは続行\n","            continue\n","\n","    pbar.close()\n","\n","    print(\"\\n=== 完了レポート ===\")\n","    print(f\"作成: {created_count}  / スキップ: {skipped_count}\")\n","    if ERROR_LOG:\n","        print(f\"\\nエラー {len(ERROR_LOG)} 件（一部抜粋）:\")\n","        for live_id, msg in ERROR_LOG[:20]:\n","            print(f\"  live_id={live_id}: {msg}\")\n","\n","\n","# 実行\n","main()\n"]}]}