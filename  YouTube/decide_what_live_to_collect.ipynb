{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNqRhQuidJvPR6jPyhh/bz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"D7bTpznq-TOT"},"outputs":[],"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\n","\"\"\"\n","01_planner_daily.py  (start-only 7-day filter + dedupe ledger + daily cap)\n","- YouTube Data API v3 を使って、キーワード=「雑談」× 過去DAYS日「開始」の completedライブを収集\n","- 抽出条件:\n","    1) eventType=completed（終了済みライブ）\n","    2) actualStartTime と actualEndTime の両方が存在\n","    3) actualStartTime が「今(UTC)から DAYS 日以内」\n","- その後、viewCount 降順で上位 DAILY_TARGET 件（新規のみ）を選抜\n","- 重複防止: BASE_DIR/_ledger/collected_video_ids.csv で過去収集済みの video_id を除外\n","- 出力:\n","    BASE_DIR/run_id/\n","      ├─ manifests/\n","      │    ├─ manifest_<run_id>.csv\n","      │    └─ assignments_audio_<run_id>.csv  … shard_id(0..SHARDS-1) にラウンドロビン割当\n","      └─ （ワーカーが audio/chat/meta/logs/tmp を後で自動生成）\n","\"\"\"\n","\n","from __future__ import annotations\n","import os, sys, time, csv, datetime as dt, requests, re\n","from typing import List, Dict, Optional, Set\n","\n","try:\n","    from tqdm import tqdm\n","    HAS_TQDM = True\n","\n","except Exception:\n","    HAS_TQDM = False\n","\n","# ====== 保存先（絶対パス）======\n","BASE_DIR = \"ここに使う予定のディレクトリの絶対パスを入れてください\"\n","# =================================\n","\n","# ====== 設定 ======\n","API_KEY = \"ここに機密コードを入れてください\"  # ← ここに API キー\n","QUERY = \"雑談\"\n","REGION_CODE = \"JP\"\n","DAYS = 7\n","ORDER_MODE = \"viewCount\"   # 'viewCount' or 'date'\n","SEARCH_PAGE_LIMIT = 40     # 1ページ最大50件\n","DAILY_TARGET = 500        # 今日の新規収集上限（最大100件）\n","\n","SLEEP = 0.10               # API呼び出しの間隔(秒)\n","SHARDS = 2                 # 並列は2本（shard 0/1）\n","# ===================\n","\n","YAPI = \"https://www.googleapis.com/youtube/v3\"\n","\n","# RFC3339（小数秒あり/なし, 末尾Z or +00:00 等）を堅牢にUTC naiveに直す\n","_RFC3339_Z = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?Z$\")\n","\n","def ensure_dir(p: str):\n","    os.makedirs(p, exist_ok=True)\n","\n","def parse_rfc3339_to_utc_naive(s: str) -> Optional[dt.datetime]:\n","    if not s:\n","        return None\n","    try:\n","        if _RFC3339_Z.match(s):\n","            s = s[:-1] + \"+00:00\"\n","        dt_with_tz = dt.datetime.fromisoformat(s)\n","        return dt_with_tz.astimezone(dt.timezone.utc).replace(tzinfo=None)\n","    except Exception:\n","        return None\n","\n","def now_utc() -> dt.datetime:\n","    return dt.datetime.utcnow()\n","\n","def within_days_from_start_only(start_iso: str, days: int) -> bool:\n","    t = parse_rfc3339_to_utc_naive(start_iso)\n","    if t is None:\n","        return False\n","    return (now_utc() - t) <= dt.timedelta(days=days)\n","\n","def http_get(url, params):\n","    r = requests.get(url, params=params, timeout=30)\n","    r.raise_for_status()\n","    return r.json()\n","\n","def url_of(vid: str) -> str:\n","    return f\"https://www.youtube.com/watch?v={vid}\"\n","\n","# ---------- ledger ----------\n","def ledger_path() -> str:\n","    led_dir = os.path.join(BASE_DIR, \"_ledger\")\n","    ensure_dir(led_dir)\n","    return os.path.join(led_dir, \"collected_video_ids.csv\")\n","\n","def load_collected_ids() -> Set[str]:\n","    path = ledger_path()\n","    ids: Set[str] = set()\n","    if not os.path.exists(path):\n","        return ids\n","    with open(path, \"r\", encoding=\"utf-8\") as f:\n","        reader = csv.DictReader(f)\n","        for row in reader:\n","            vid = (row.get(\"video_id\") or \"\").strip()\n","            if re.fullmatch(r\"^[\\w-]{11}$\", vid):\n","                ids.add(vid)\n","    return ids\n","\n","def append_to_ledger(run_id: str, rows: List[Dict]):\n","    path = ledger_path()\n","    file_exists = os.path.exists(path)\n","    with open(path, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n","        fieldnames = [\"date_utc\", \"run_id\", \"video_id\", \"channel\", \"title\", \"start_utc\", \"view_count\", \"url\"]\n","        w = csv.DictWriter(f, fieldnames=fieldnames)\n","        if not file_exists:\n","            w.writeheader()\n","        today = now_utc().strftime(\"%Y-%m-%d\")\n","        for r in rows:\n","            w.writerow({\n","                \"date_utc\": today,\n","                \"run_id\": run_id,\n","                \"video_id\": r[\"video_id\"],\n","                \"channel\": r[\"channel\"],\n","                \"title\": r[\"title\"],\n","                \"start_utc\": r[\"start_utc\"],\n","                \"view_count\": r[\"view_count\"],\n","                \"url\": r[\"url\"],\n","            })\n","\n","# ---------- YouTube API ----------\n","def search_completed_ids(order_mode: str) -> List[str]:\n","    if order_mode not in (\"viewCount\", \"date\"):\n","        raise ValueError(\"ORDER_MODE must be 'viewCount' or 'date'.\")\n","\n","    ids, page_token, pages = [], None, 0\n","    print(f\"[search.list] q={QUERY or '-'} | region={REGION_CODE or '-'} | eventType=completed | order={order_mode}\")\n","\n","    while pages < SEARCH_PAGE_LIMIT:\n","        params = {\n","            \"key\": API_KEY,\n","            \"part\": \"snippet\",\n","            \"type\": \"video\",\n","            \"eventType\": \"completed\",\n","            \"order\": order_mode,\n","            \"maxResults\": 50,\n","        }\n","        if QUERY:\n","            params[\"q\"] = QUERY\n","        if REGION_CODE:\n","            params[\"regionCode\"] = REGION_CODE\n","        if page_token:\n","            params[\"pageToken\"] = page_token\n","\n","        data = http_get(f\"{YAPI}/search\", params)\n","        items = data.get(\"items\", [])\n","        page_ids = []\n","        for it in items:\n","            vid = (it.get(\"id\") or {}).get(\"videoId\")\n","            if vid:\n","                page_ids.append(vid)\n","        ids.extend(page_ids)\n","\n","        pages += 1\n","        print(f\"  - page {pages:02d}: {len(page_ids):2d} 件 / 累計(raw) {len(ids):3d} 件\")\n","        page_token = data.get(\"nextPageToken\")\n","        if not page_token:\n","            break\n","        time.sleep(SLEEP)\n","\n","    unique = list(dict.fromkeys(ids))\n","    print(f\"[search.list] 終了: ユニーク {len(unique)} 件（raw {len(ids)} 件）\")\n","    return unique\n","\n","def fetch_videos_detail(video_ids: List[str]) -> List[Dict]:\n","    out = []\n","    rng = range(0, len(video_ids), 50)\n","    if HAS_TQDM:\n","        rng = tqdm(rng, desc=\"fetch videos detail (batches of 50)\", unit=\"batch\", leave=False)\n","    for i in rng:\n","        batch = video_ids[i:i+50]\n","        if not batch:\n","            break\n","        params = {\n","            \"key\": API_KEY,\n","            \"part\": \"snippet,statistics,liveStreamingDetails\",\n","            \"id\": \",\".join(batch),\n","            \"maxResults\": 50,\n","        }\n","        data = http_get(f\"{YAPI}/videos\", params)\n","        out.extend(data.get(\"items\", []))\n","        time.sleep(SLEEP)\n","    if HAS_TQDM:\n","        print()\n","    return out\n","\n","def run_id_str() -> str:\n","    return dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","def main():\n","    if not API_KEY:\n","        print(\"ERROR: API_KEY を設定してください。\", file=sys.stderr)\n","        sys.exit(2)\n","\n","    ensure_dir(BASE_DIR)\n","\n","    rid = run_id_str()\n","    base = os.path.join(BASE_DIR, rid)\n","    mani_dir = os.path.join(base, \"manifests\")\n","    ensure_dir(mani_dir)\n","\n","    print(f\"🗓️ run_id: {rid}\")\n","    print(f\"📁 RUN_DIR: {base}\")\n","\n","    # すでに収集済みの video_id セット\n","    collected = load_collected_ids()\n","    print(f\"[ledger] 既存の収集済み video_id: {len(collected)} 件\")\n","\n","    ids = search_completed_ids(ORDER_MODE)\n","    videos = fetch_videos_detail(ids)\n","\n","    rows = []\n","    it = videos\n","    if HAS_TQDM:\n","        it = tqdm(videos, desc=\"filter & collect\", unit=\"vid\", leave=False)\n","\n","    filtered_cnt = 0\n","    skipped_no_time = 0\n","    skipped_old = 0\n","    skipped_dup = 0\n","\n","    for v in it:\n","        sn = v.get(\"snippet\") or {}\n","        st = v.get(\"statistics\") or {}\n","        lsd = v.get(\"liveStreamingDetails\") or {}\n","\n","        start = lsd.get(\"actualStartTime\") or \"\"\n","        end   = lsd.get(\"actualEndTime\")   or \"\"\n","\n","        if not (start and end):\n","            skipped_no_time += 1\n","            continue\n","        if not within_days_from_start_only(start, DAYS):\n","            skipped_old += 1\n","            continue\n","\n","        vid = v.get(\"id\")\n","        if vid in collected:\n","            skipped_dup += 1\n","            continue\n","\n","        views = int(st.get(\"viewCount\", \"0\") or 0)\n","\n","        rows.append({\n","            \"video_id\": vid,\n","            \"title\": sn.get(\"title\", \"\"),\n","            \"channel\": sn.get(\"channelTitle\", \"\"),\n","            \"start_utc\": (parse_rfc3339_to_utc_naive(start).strftime(\"%Y-%m-%dT%H:%M:%SZ\") if start else \"\"),\n","            \"view_count\": views,\n","            \"url\": url_of(vid),\n","        })\n","        filtered_cnt += 1\n","    if HAS_TQDM:\n","        print()\n","\n","    if not rows:\n","        print(f\"→ フィルタ後 0 件でした（条件: start & end が存在 かつ start が直近 {DAYS} 日 かつ 過去未収集）\")\n","        sys.exit(0)\n","\n","    # viewCount 降順 → 今日の新規を最大 DAILY_TARGET 件に制限\n","    rows.sort(key=lambda r: r[\"view_count\"], reverse=True)\n","    rows = rows[:DAILY_TARGET]\n","\n","    # manifest 保存\n","    manifest_csv = os.path.join(mani_dir, f\"manifest_{rid}.csv\")\n","    with open(manifest_csv, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n","        w = csv.DictWriter(f, fieldnames=[\"rank\", \"video_id\", \"channel\", \"title\", \"view_count\", \"start_utc\", \"url\"])\n","        w.writeheader()\n","        for i, r in enumerate(rows, 1):\n","            w.writerow({\"rank\": i, **r})\n","\n","    # assignments 保存（0..SHARDS-1 へラウンドロビン）\n","    assign_csv = os.path.join(mani_dir, f\"assignments_audio_{rid}.csv\")\n","    with open(assign_csv, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n","        w = csv.DictWriter(f, fieldnames=[\"video_id\", \"shard_id\"])\n","        w.writeheader()\n","        for i, r in enumerate(rows):\n","            w.writerow({\"video_id\": r[\"video_id\"], \"shard_id\": i % SHARDS})\n","\n","    # ledger へ追記（今日選んだ新規だけ）\n","    append_to_ledger(rid, rows)\n","\n","    print(f\"🔎 search.list({ORDER_MODE}) ヒット（ユニーク）: {len(ids)} 件\")\n","    print(f\"   - 除外: 時刻欠落 {skipped_no_time} / 古い {skipped_old} / 過去収集 {skipped_dup}\")\n","    print(f\"📝 manifest 保存: {manifest_csv} | 今日の新規 {len(rows)} 件（上限 {DAILY_TARGET}）\")\n","    print(f\"🗂️ assignments 保存: {assign_csv} | shard=0..{SHARDS-1}\")\n","\n","    top_preview = min(10, len(rows))\n","    print(\"\\n=== プレビュー（上位 10 件 / view_count 降順, start基準, 新規のみ）=== \")\n","    print(f\"{'Rank':>4}  {'Views':>10}  {'Channel':<28}  {'Title':<42}  URL\")\n","    print(\"-\"*120)\n","    for i, r in enumerate(rows[:top_preview], 1):\n","        ch = (r[\"channel\"][:28]).ljust(28)\n","        ti = (r[\"title\"][:42]).ljust(42)\n","        print(f\"{i:>4}  {r['view_count']:>10,}  {ch}  {ti}  {r['url']}\")\n","\n","    print(f\"\\n✅ プランナー完了。次は **ワーカー (shard=0,1)** で音声＋チャットを取得してください。\")\n","    print(f\"   - manifest : {manifest_csv}\")\n","    print(f\"   - assign   : {assign_csv}\")\n","    print(f\"   - 保存ルート: {base}\")\n","    print(f\"run id:{rid}\")\n","\n","\n","if __name__ == \"__main__\":\n","    try:\n","        main()\n","    except requests.HTTPError as e:\n","        print(\"HTTPError:\", e.response.status_code, e.response.text[:400], file=sys.stderr)\n","        sys.exit(2)\n","    except Exception as e:\n","        print(\"Error:\", repr(e), file=sys.stderr)\n","        sys.exit(3)\n"]}]}