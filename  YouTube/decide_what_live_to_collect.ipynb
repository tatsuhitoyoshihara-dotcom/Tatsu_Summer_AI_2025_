{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNqRhQuidJvPR6jPyhh/bz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"D7bTpznq-TOT"},"outputs":[],"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\n","\"\"\"\n","01_planner_daily.py  (start-only 7-day filter + dedupe ledger + daily cap)\n","- YouTube Data API v3 ã‚’ä½¿ã£ã¦ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰=ã€Œé›‘è«‡ã€Ã— éå»DAYSæ—¥ã€Œé–‹å§‹ã€ã® completedãƒ©ã‚¤ãƒ–ã‚’åé›†\n","- æŠ½å‡ºæ¡ä»¶:\n","    1) eventType=completedï¼ˆçµ‚äº†æ¸ˆã¿ãƒ©ã‚¤ãƒ–ï¼‰\n","    2) actualStartTime ã¨ actualEndTime ã®ä¸¡æ–¹ãŒå­˜åœ¨\n","    3) actualStartTime ãŒã€Œä»Š(UTC)ã‹ã‚‰ DAYS æ—¥ä»¥å†…ã€\n","- ãã®å¾Œã€viewCount é™é †ã§ä¸Šä½ DAILY_TARGET ä»¶ï¼ˆæ–°è¦ã®ã¿ï¼‰ã‚’é¸æŠœ\n","- é‡è¤‡é˜²æ­¢: BASE_DIR/_ledger/collected_video_ids.csv ã§éå»åé›†æ¸ˆã¿ã® video_id ã‚’é™¤å¤–\n","- å‡ºåŠ›:\n","    BASE_DIR/run_id/\n","      â”œâ”€ manifests/\n","      â”‚    â”œâ”€ manifest_<run_id>.csv\n","      â”‚    â””â”€ assignments_audio_<run_id>.csv  â€¦ shard_id(0..SHARDS-1) ã«ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³å‰²å½“\n","      â””â”€ ï¼ˆãƒ¯ãƒ¼ã‚«ãƒ¼ãŒ audio/chat/meta/logs/tmp ã‚’å¾Œã§è‡ªå‹•ç”Ÿæˆï¼‰\n","\"\"\"\n","\n","from __future__ import annotations\n","import os, sys, time, csv, datetime as dt, requests, re\n","from typing import List, Dict, Optional, Set\n","\n","try:\n","    from tqdm import tqdm\n","    HAS_TQDM = True\n","\n","except Exception:\n","    HAS_TQDM = False\n","\n","# ====== ä¿å­˜å…ˆï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ï¼‰======\n","BASE_DIR = \"ã“ã“ã«ä½¿ã†äºˆå®šã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹ã‚’å…¥ã‚Œã¦ãã ã•ã„\"\n","# =================================\n","\n","# ====== è¨­å®š ======\n","API_KEY = \"ã“ã“ã«æ©Ÿå¯†ã‚³ãƒ¼ãƒ‰ã‚’å…¥ã‚Œã¦ãã ã•ã„\"  # â† ã“ã“ã« API ã‚­ãƒ¼\n","QUERY = \"é›‘è«‡\"\n","REGION_CODE = \"JP\"\n","DAYS = 7\n","ORDER_MODE = \"viewCount\"   # 'viewCount' or 'date'\n","SEARCH_PAGE_LIMIT = 40     # 1ãƒšãƒ¼ã‚¸æœ€å¤§50ä»¶\n","DAILY_TARGET = 500        # ä»Šæ—¥ã®æ–°è¦åé›†ä¸Šé™ï¼ˆæœ€å¤§100ä»¶ï¼‰\n","\n","SLEEP = 0.10               # APIå‘¼ã³å‡ºã—ã®é–“éš”(ç§’)\n","SHARDS = 2                 # ä¸¦åˆ—ã¯2æœ¬ï¼ˆshard 0/1ï¼‰\n","# ===================\n","\n","YAPI = \"https://www.googleapis.com/youtube/v3\"\n","\n","# RFC3339ï¼ˆå°æ•°ç§’ã‚ã‚Š/ãªã—, æœ«å°¾Z or +00:00 ç­‰ï¼‰ã‚’å …ç‰¢ã«UTC naiveã«ç›´ã™\n","_RFC3339_Z = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?Z$\")\n","\n","def ensure_dir(p: str):\n","    os.makedirs(p, exist_ok=True)\n","\n","def parse_rfc3339_to_utc_naive(s: str) -> Optional[dt.datetime]:\n","    if not s:\n","        return None\n","    try:\n","        if _RFC3339_Z.match(s):\n","            s = s[:-1] + \"+00:00\"\n","        dt_with_tz = dt.datetime.fromisoformat(s)\n","        return dt_with_tz.astimezone(dt.timezone.utc).replace(tzinfo=None)\n","    except Exception:\n","        return None\n","\n","def now_utc() -> dt.datetime:\n","    return dt.datetime.utcnow()\n","\n","def within_days_from_start_only(start_iso: str, days: int) -> bool:\n","    t = parse_rfc3339_to_utc_naive(start_iso)\n","    if t is None:\n","        return False\n","    return (now_utc() - t) <= dt.timedelta(days=days)\n","\n","def http_get(url, params):\n","    r = requests.get(url, params=params, timeout=30)\n","    r.raise_for_status()\n","    return r.json()\n","\n","def url_of(vid: str) -> str:\n","    return f\"https://www.youtube.com/watch?v={vid}\"\n","\n","# ---------- ledger ----------\n","def ledger_path() -> str:\n","    led_dir = os.path.join(BASE_DIR, \"_ledger\")\n","    ensure_dir(led_dir)\n","    return os.path.join(led_dir, \"collected_video_ids.csv\")\n","\n","def load_collected_ids() -> Set[str]:\n","    path = ledger_path()\n","    ids: Set[str] = set()\n","    if not os.path.exists(path):\n","        return ids\n","    with open(path, \"r\", encoding=\"utf-8\") as f:\n","        reader = csv.DictReader(f)\n","        for row in reader:\n","            vid = (row.get(\"video_id\") or \"\").strip()\n","            if re.fullmatch(r\"^[\\w-]{11}$\", vid):\n","                ids.add(vid)\n","    return ids\n","\n","def append_to_ledger(run_id: str, rows: List[Dict]):\n","    path = ledger_path()\n","    file_exists = os.path.exists(path)\n","    with open(path, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n","        fieldnames = [\"date_utc\", \"run_id\", \"video_id\", \"channel\", \"title\", \"start_utc\", \"view_count\", \"url\"]\n","        w = csv.DictWriter(f, fieldnames=fieldnames)\n","        if not file_exists:\n","            w.writeheader()\n","        today = now_utc().strftime(\"%Y-%m-%d\")\n","        for r in rows:\n","            w.writerow({\n","                \"date_utc\": today,\n","                \"run_id\": run_id,\n","                \"video_id\": r[\"video_id\"],\n","                \"channel\": r[\"channel\"],\n","                \"title\": r[\"title\"],\n","                \"start_utc\": r[\"start_utc\"],\n","                \"view_count\": r[\"view_count\"],\n","                \"url\": r[\"url\"],\n","            })\n","\n","# ---------- YouTube API ----------\n","def search_completed_ids(order_mode: str) -> List[str]:\n","    if order_mode not in (\"viewCount\", \"date\"):\n","        raise ValueError(\"ORDER_MODE must be 'viewCount' or 'date'.\")\n","\n","    ids, page_token, pages = [], None, 0\n","    print(f\"[search.list] q={QUERY or '-'} | region={REGION_CODE or '-'} | eventType=completed | order={order_mode}\")\n","\n","    while pages < SEARCH_PAGE_LIMIT:\n","        params = {\n","            \"key\": API_KEY,\n","            \"part\": \"snippet\",\n","            \"type\": \"video\",\n","            \"eventType\": \"completed\",\n","            \"order\": order_mode,\n","            \"maxResults\": 50,\n","        }\n","        if QUERY:\n","            params[\"q\"] = QUERY\n","        if REGION_CODE:\n","            params[\"regionCode\"] = REGION_CODE\n","        if page_token:\n","            params[\"pageToken\"] = page_token\n","\n","        data = http_get(f\"{YAPI}/search\", params)\n","        items = data.get(\"items\", [])\n","        page_ids = []\n","        for it in items:\n","            vid = (it.get(\"id\") or {}).get(\"videoId\")\n","            if vid:\n","                page_ids.append(vid)\n","        ids.extend(page_ids)\n","\n","        pages += 1\n","        print(f\"  - page {pages:02d}: {len(page_ids):2d} ä»¶ / ç´¯è¨ˆ(raw) {len(ids):3d} ä»¶\")\n","        page_token = data.get(\"nextPageToken\")\n","        if not page_token:\n","            break\n","        time.sleep(SLEEP)\n","\n","    unique = list(dict.fromkeys(ids))\n","    print(f\"[search.list] çµ‚äº†: ãƒ¦ãƒ‹ãƒ¼ã‚¯ {len(unique)} ä»¶ï¼ˆraw {len(ids)} ä»¶ï¼‰\")\n","    return unique\n","\n","def fetch_videos_detail(video_ids: List[str]) -> List[Dict]:\n","    out = []\n","    rng = range(0, len(video_ids), 50)\n","    if HAS_TQDM:\n","        rng = tqdm(rng, desc=\"fetch videos detail (batches of 50)\", unit=\"batch\", leave=False)\n","    for i in rng:\n","        batch = video_ids[i:i+50]\n","        if not batch:\n","            break\n","        params = {\n","            \"key\": API_KEY,\n","            \"part\": \"snippet,statistics,liveStreamingDetails\",\n","            \"id\": \",\".join(batch),\n","            \"maxResults\": 50,\n","        }\n","        data = http_get(f\"{YAPI}/videos\", params)\n","        out.extend(data.get(\"items\", []))\n","        time.sleep(SLEEP)\n","    if HAS_TQDM:\n","        print()\n","    return out\n","\n","def run_id_str() -> str:\n","    return dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","def main():\n","    if not API_KEY:\n","        print(\"ERROR: API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚\", file=sys.stderr)\n","        sys.exit(2)\n","\n","    ensure_dir(BASE_DIR)\n","\n","    rid = run_id_str()\n","    base = os.path.join(BASE_DIR, rid)\n","    mani_dir = os.path.join(base, \"manifests\")\n","    ensure_dir(mani_dir)\n","\n","    print(f\"ğŸ—“ï¸ run_id: {rid}\")\n","    print(f\"ğŸ“ RUN_DIR: {base}\")\n","\n","    # ã™ã§ã«åé›†æ¸ˆã¿ã® video_id ã‚»ãƒƒãƒˆ\n","    collected = load_collected_ids()\n","    print(f\"[ledger] æ—¢å­˜ã®åé›†æ¸ˆã¿ video_id: {len(collected)} ä»¶\")\n","\n","    ids = search_completed_ids(ORDER_MODE)\n","    videos = fetch_videos_detail(ids)\n","\n","    rows = []\n","    it = videos\n","    if HAS_TQDM:\n","        it = tqdm(videos, desc=\"filter & collect\", unit=\"vid\", leave=False)\n","\n","    filtered_cnt = 0\n","    skipped_no_time = 0\n","    skipped_old = 0\n","    skipped_dup = 0\n","\n","    for v in it:\n","        sn = v.get(\"snippet\") or {}\n","        st = v.get(\"statistics\") or {}\n","        lsd = v.get(\"liveStreamingDetails\") or {}\n","\n","        start = lsd.get(\"actualStartTime\") or \"\"\n","        end   = lsd.get(\"actualEndTime\")   or \"\"\n","\n","        if not (start and end):\n","            skipped_no_time += 1\n","            continue\n","        if not within_days_from_start_only(start, DAYS):\n","            skipped_old += 1\n","            continue\n","\n","        vid = v.get(\"id\")\n","        if vid in collected:\n","            skipped_dup += 1\n","            continue\n","\n","        views = int(st.get(\"viewCount\", \"0\") or 0)\n","\n","        rows.append({\n","            \"video_id\": vid,\n","            \"title\": sn.get(\"title\", \"\"),\n","            \"channel\": sn.get(\"channelTitle\", \"\"),\n","            \"start_utc\": (parse_rfc3339_to_utc_naive(start).strftime(\"%Y-%m-%dT%H:%M:%SZ\") if start else \"\"),\n","            \"view_count\": views,\n","            \"url\": url_of(vid),\n","        })\n","        filtered_cnt += 1\n","    if HAS_TQDM:\n","        print()\n","\n","    if not rows:\n","        print(f\"â†’ ãƒ•ã‚£ãƒ«ã‚¿å¾Œ 0 ä»¶ã§ã—ãŸï¼ˆæ¡ä»¶: start & end ãŒå­˜åœ¨ ã‹ã¤ start ãŒç›´è¿‘ {DAYS} æ—¥ ã‹ã¤ éå»æœªåé›†ï¼‰\")\n","        sys.exit(0)\n","\n","    # viewCount é™é † â†’ ä»Šæ—¥ã®æ–°è¦ã‚’æœ€å¤§ DAILY_TARGET ä»¶ã«åˆ¶é™\n","    rows.sort(key=lambda r: r[\"view_count\"], reverse=True)\n","    rows = rows[:DAILY_TARGET]\n","\n","    # manifest ä¿å­˜\n","    manifest_csv = os.path.join(mani_dir, f\"manifest_{rid}.csv\")\n","    with open(manifest_csv, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n","        w = csv.DictWriter(f, fieldnames=[\"rank\", \"video_id\", \"channel\", \"title\", \"view_count\", \"start_utc\", \"url\"])\n","        w.writeheader()\n","        for i, r in enumerate(rows, 1):\n","            w.writerow({\"rank\": i, **r})\n","\n","    # assignments ä¿å­˜ï¼ˆ0..SHARDS-1 ã¸ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ï¼‰\n","    assign_csv = os.path.join(mani_dir, f\"assignments_audio_{rid}.csv\")\n","    with open(assign_csv, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n","        w = csv.DictWriter(f, fieldnames=[\"video_id\", \"shard_id\"])\n","        w.writeheader()\n","        for i, r in enumerate(rows):\n","            w.writerow({\"video_id\": r[\"video_id\"], \"shard_id\": i % SHARDS})\n","\n","    # ledger ã¸è¿½è¨˜ï¼ˆä»Šæ—¥é¸ã‚“ã æ–°è¦ã ã‘ï¼‰\n","    append_to_ledger(rid, rows)\n","\n","    print(f\"ğŸ” search.list({ORDER_MODE}) ãƒ’ãƒƒãƒˆï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ï¼‰: {len(ids)} ä»¶\")\n","    print(f\"   - é™¤å¤–: æ™‚åˆ»æ¬ è½ {skipped_no_time} / å¤ã„ {skipped_old} / éå»åé›† {skipped_dup}\")\n","    print(f\"ğŸ“ manifest ä¿å­˜: {manifest_csv} | ä»Šæ—¥ã®æ–°è¦ {len(rows)} ä»¶ï¼ˆä¸Šé™ {DAILY_TARGET}ï¼‰\")\n","    print(f\"ğŸ—‚ï¸ assignments ä¿å­˜: {assign_csv} | shard=0..{SHARDS-1}\")\n","\n","    top_preview = min(10, len(rows))\n","    print(\"\\n=== ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä¸Šä½ 10 ä»¶ / view_count é™é †, startåŸºæº–, æ–°è¦ã®ã¿ï¼‰=== \")\n","    print(f\"{'Rank':>4}  {'Views':>10}  {'Channel':<28}  {'Title':<42}  URL\")\n","    print(\"-\"*120)\n","    for i, r in enumerate(rows[:top_preview], 1):\n","        ch = (r[\"channel\"][:28]).ljust(28)\n","        ti = (r[\"title\"][:42]).ljust(42)\n","        print(f\"{i:>4}  {r['view_count']:>10,}  {ch}  {ti}  {r['url']}\")\n","\n","    print(f\"\\nâœ… ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼å®Œäº†ã€‚æ¬¡ã¯ **ãƒ¯ãƒ¼ã‚«ãƒ¼ (shard=0,1)** ã§éŸ³å£°ï¼‹ãƒãƒ£ãƒƒãƒˆã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚\")\n","    print(f\"   - manifest : {manifest_csv}\")\n","    print(f\"   - assign   : {assign_csv}\")\n","    print(f\"   - ä¿å­˜ãƒ«ãƒ¼ãƒˆ: {base}\")\n","    print(f\"run id:{rid}\")\n","\n","\n","if __name__ == \"__main__\":\n","    try:\n","        main()\n","    except requests.HTTPError as e:\n","        print(\"HTTPError:\", e.response.status_code, e.response.text[:400], file=sys.stderr)\n","        sys.exit(2)\n","    except Exception as e:\n","        print(\"Error:\", repr(e), file=sys.stderr)\n","        sys.exit(3)\n"]}]}