{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP87FtHuMNYKNRan8gqCrb3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-nSbtnvyv-Vg"},"outputs":[],"source":["#ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’æŒã¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’10å€‹è¤‡è£½ã—ã¦ã€SHARD_IDã®ã¿ã‚’ãã‚Œãã‚Œãƒ•ã‚¡ã‚¤ãƒ«ã®æ•°ã«å¯¾å¿œã•ã›ã¦ï¼ˆ10å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãªã‚‰0-9ã®å€¤ã‚’ãã‚Œãã‚Œã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ç™»éŒ²ã™ã‚‹ã€‚ï¼‰å®Ÿè¡Œã—ã¾ã™ã€‚\n","#ã“ã‚Œã«è¿½åŠ ã—ã¦ã€RUN_IDã‚‚decide_what_live_to_collect.ipynbã§å–å¾—ã—ãŸå€¤ã‚’ã¯ã‚è¾¼ã¿ã¾ã™ã€‚\n","\n","# =========================\n","# Robust Twitch Worker v2 (crash-resume / multi-shard / ledger+locks in GCS)\n","# =========================\n","# ä¾å­˜: google-cloud-storage, pandas, requests, pytz, tqdm, yt-dlp, ffmpeg(TwitchDownloaderCLIã¯åˆ¥)\n","# å½¹å‰²:\n","#  - assignments_{RUN_ID}.csv ã§å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸ VOD ã‚’ã€ã“ã® SHARD_ID ãŒæ‹…å½“\n","#  - å„ VOD ã«ã¤ã„ã¦ chat â†’ audio(m4a) â†’ mp4 ã‚’é †ã«å®Ÿæ–½\n","#  - å„å·¥ç¨‹ã®å®Œäº†/å¤±æ•—ã¯ ledger.csv ã« â€œå®‰å…¨ã«â€ åæ˜ ï¼ˆä¸–ä»£ä¸€è‡´ã®æ¥½è¦³ãƒ­ãƒƒã‚¯ + ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰\n","#  - GCS lockï¼ˆlocks/<vod>.lockï¼‰ã¯å¿ƒæ‹(heartbeat)ã§å»¶å‘½ã€ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ™‚ã¯ TTL è¶…éã§ä»–ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒå¥ªå–å¯èƒ½\n","#  - å…¨æ»…å¾Œã§ã‚‚ ledger è‡ªå‹•å¾©å…ƒãƒ»å†èµ·å‹•ã ã‘ã§ç¶šè¡Œ\n","# =========================\n","\n","import os, re, json, time, subprocess, shutil, pathlib, math, signal, threading, socket, uuid\n","from typing import Optional, Tuple, List\n","from datetime import datetime, timezone, timedelta\n","\n","import pytz, requests, pandas as pd\n","from tqdm.auto import tqdm\n","from google.cloud import storage\n","\n","# ========= ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š =========\n","RUN_ID   = os.environ.get(\"RUN_ID\", \"20250910_190657\")  # ä¾‹: \"YYYYmmdd_HHMMSS\"\n","SHARD_ID = int(os.environ.get(\"SHARD_ID\", \"0\"))         # 0..9\n","SHARD_COUNT = int(os.environ.get(\"SHARD_COUNT\", \"10\"))\n","\n","CLIENT_ID     = os.environ.get(\"TWITCH_CLIENT_ID\", 'ã“ã“ã«æ©Ÿå¯†ã‚³ãƒ¼ãƒ‰ã‚’å…¥ã‚Œã¾ã™')\n","CLIENT_SECRET = os.environ.get(\"TWITCH_CLIENT_SECRET\", 'ã“ã“ã«æ©Ÿå¯†ã‚³ãƒ¼ãƒ‰ã‚’å…¥ã‚Œã¾ã™')\n","\n","GCS_BUCKET      = os.environ.get(\"GCS_BUCKET\", \"dena-ai-intern-yoshihara-data\")\n","GCS_ROOT_PREFIX = os.environ.get(\"GCS_ROOT_PREFIX\", \"twitch_v2\")\n","\n","API_BASE_URL = \"https://api.twitch.tv/helix\"\n","AUTH_URL     = \"https://id.twitch.tv/oauth2/token\"\n","\n","TWITCHDL = os.environ.get(\"TWITCHDL\", \"/home/jupyter/Twitch_data_collection/TwitchDownloaderCLI\")\n","\n","# ========= å›ºå®šãƒ«ãƒ¼ãƒˆï¼ˆã©ã“ã‹ã‚‰å®Ÿè¡Œã—ã¦ã‚‚åŒã˜å ´æ‰€ã‚’ä½¿ã†ï¼‰=========\n","ROOT_DIR  = \"/home/jupyter/Twitch_Pipeline\"\n","STATE_DIR = os.path.join(ROOT_DIR, \"state_v2\")                  # å…±æœ‰å°å¸³/å‰²å½“ã®ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥\n","TMP_DIR   = os.path.join(ROOT_DIR, f\"temp_downloads_v2/shard_{SHARD_ID}\")  # ãƒ¯ãƒ¼ã‚«ãƒ¼ã”ã¨ã®ä¸€æ™‚é ˜åŸŸ\n","\n","os.makedirs(STATE_DIR, exist_ok=True)\n","os.makedirs(TMP_DIR, exist_ok=True)\n","\n","# ========= GCS ã‚­ãƒ¼é¡ =========\n","def gcs_key(prefix: str, filename: str) -> str:\n","    return f\"{GCS_ROOT_PREFIX}/{RUN_ID}/{prefix}/{filename}\"\n","\n","LEDGER_KEY            = gcs_key(\"manifests\", \"ledger.csv\")\n","LEDGER_BACKUP_KEY     = gcs_key(\"manifests\", \"ledger.prev.csv\")\n","ASSIGN_KEY            = gcs_key(\"manifests\", f\"assignments_{RUN_ID}.csv\")\n","LOCK_PREFIX           = f\"{GCS_ROOT_PREFIX}/{RUN_ID}/locks\"\n","\n","LEDGER_LOCAL          = os.path.join(STATE_DIR, f\"ledger_{RUN_ID}.csv\")\n","LEDGER_BACKUP_LOCAL   = os.path.join(STATE_DIR, f\"ledger_{RUN_ID}.prev.csv\")\n","ASSIGN_LOCAL          = os.path.join(STATE_DIR, f\"assignments_{RUN_ID}.csv\")\n","\n","# ========= ãƒ­ã‚°ç½®ãå ´ =========\n","LOG_ROOT = os.path.join(STATE_DIR, \"logs\", RUN_ID)\n","os.makedirs(LOG_ROOT, exist_ok=True)\n","\n","# ========= ã‚°ãƒ­ãƒ¼ãƒãƒ« =========\n","JST = pytz.timezone(\"Asia/Tokyo\")\n","def jst_now_iso() -> str: return datetime.now(JST).isoformat()\n","\n","def seconds_to_hms(sec: int) -> str:\n","    h = sec // 3600; m = (sec % 3600) // 60; s = sec % 60\n","    return f\"{h:02d}:{m:02d}:{s:02d}\"\n","\n","print(f\"ğŸ§µ Worker èµ·å‹• | RUN_ID={RUN_ID} | SHARD_ID={SHARD_ID} | ROOT={ROOT_DIR}\")\n","\n","# ========= GCS I/O =========\n","def gcs_client() -> storage.Client: return storage.Client()\n","\n","def gcs_download(key: str, local_path: str) -> bool:\n","    \"\"\"\n","    GCS ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€‚0ãƒã‚¤ãƒˆã¯ä¸æ­£ã¨ã—ã¦ False ã‚’è¿”ã™ã€‚\n","    \"\"\"\n","    b = gcs_client().bucket(GCS_BUCKET); bl = b.blob(key)\n","    if not bl.exists():\n","        print(f\"âš ï¸ GCSã«å­˜åœ¨ã—ã¾ã›ã‚“: gs://{GCS_BUCKET}/{key}\")\n","        return False\n","    os.makedirs(os.path.dirname(local_path), exist_ok=True)\n","    bl.download_to_filename(local_path)\n","    try:\n","        bl.reload()\n","        if (bl.size or 0) == 0:\n","            print(f\"âš ï¸ ç©ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º: gs://{GCS_BUCKET}/{key}\")\n","            return False\n","    except Exception:\n","        pass\n","    return os.path.exists(local_path) and os.path.getsize(local_path) > 0\n","\n","def _safe_remove(path: str):\n","    try:\n","        if os.path.exists(path):\n","            os.remove(path)\n","            print(f\"ğŸ§¹ deleted local: {path}\")\n","    except Exception as e:\n","        print(f\"âš ï¸ local delete failed: {path} ({e})\")\n","\n","def gcs_upload(local_path: str, key: str, *, content_type: Optional[str]=None) -> bool:\n","    \"\"\"\n","    GCSã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚µã‚¤ã‚ºä¸€è‡´ã§æ¤œè¨¼ã€‚æˆåŠŸæ™‚ True ã‚’è¿”ã™ã€‚\n","    å‘¼ã³å‡ºã—å´ã§å‰Šé™¤ãƒãƒªã‚·ãƒ¼ã‚’åˆ¶å¾¡ã™ã‚‹ï¼ˆã“ã“ã§ã¯å‰Šé™¤ã—ãªã„ï¼‰ã€‚\n","    \"\"\"\n","    if not os.path.exists(local_path):\n","        print(f\"âš ï¸ upload skipped (no local file): {local_path}\")\n","        return False\n","    b = gcs_client().bucket(GCS_BUCKET)\n","    bl = b.blob(key)\n","    kwargs = {}\n","    if content_type:\n","        kwargs[\"content_type\"] = content_type\n","    try:\n","        bl.upload_from_filename(local_path, **kwargs)\n","        bl.reload()  # size å–å¾—ã®ãŸã‚\n","        local_sz = os.path.getsize(local_path)\n","        remote_sz = int(bl.size) if bl.size is not None else None\n","        ok = (remote_sz is None) or (local_sz == remote_sz)\n","        if ok:\n","            print(f\"â˜ï¸ Uploaded: gs://{GCS_BUCKET}/{key}  (size={remote_sz})\")\n","            return True\n","        else:\n","            print(f\"âš ï¸ upload verification failed (local={local_sz}, remote={remote_sz}): gs://{GCS_BUCKET}/{key}\")\n","            return False\n","    except Exception as e:\n","        print(f\"âš ï¸ upload error: {local_path} -> gs://{GCS_BUCKET}/{key} ({e})\")\n","        return False\n","\n","def gcs_exists(key: str) -> bool:\n","    b = gcs_client().bucket(GCS_BUCKET); bl = b.blob(key)\n","    return bl.exists()\n","\n","# ========= Twitch èªè¨¼ =========\n","HEADERS = {}\n","def authenticate() -> bool:\n","    global HEADERS\n","    if not CLIENT_ID or not CLIENT_SECRET or CLIENT_ID == \"YOUR_TWITCH_CLIENT_ID\":\n","        print(\"âŒ CLIENT_ID/SECRET ã‚’è¨­å®šã—ã¦ãã ã•ã„\"); return False\n","    r = requests.post(AUTH_URL, params={\"client_id\": CLIENT_ID, \"client_secret\": CLIENT_SECRET, \"grant_type\": \"client_credentials\"})\n","    try:\n","        r.raise_for_status()\n","        token = r.json()[\"access_token\"]\n","        HEADERS = {\"Client-ID\": CLIENT_ID, \"Authorization\": f\"Bearer {token}\"}\n","        print(\"âœ… Twitch èªè¨¼OK\")\n","        return True\n","    except Exception as e:\n","        print(\"âŒ èªè¨¼å¤±æ•—:\", e, \"| resp:\", getattr(r, \"text\", \"\"))\n","        return False\n","\n","if not authenticate():\n","    raise SystemExit(\"Twitch èªè¨¼ã«å¤±æ•—\")\n","\n","# ========= Ledger Utilities (è‡ªå‹•ä¿®å¾©ï¼‹å®‰å…¨æ›´æ–°) =========\n","LEDGER_COLUMNS = [\"run_id\",\"vod_id\",\"user_name\",\"duration_seconds\",\"status\",\n","                  \"step_chat\",\"step_audio\",\"step_mp4\",\"step_whisper\",\n","                  \"last_update\",\"note\",\"shard_id\"]\n","\n","def atomic_write_csv(df: pd.DataFrame, path: str):\n","    \"\"\"å®‰å…¨ãªãƒ­ãƒ¼ã‚«ãƒ«æ›¸ãè¾¼ã¿ï¼ˆé€”ä¸­ãƒ•ã‚¡ã‚¤ãƒ«â†’ç½®æ›ï¼‰\"\"\"\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","    tmp = path + \".tmp\"\n","    df.to_csv(tmp, index=False, encoding=\"utf-8\")\n","    os.replace(tmp, path)\n","\n","def _enforce_ledger_types(df: pd.DataFrame) -> pd.DataFrame:\n","    # æ–‡å­—åˆ—åˆ—\n","    for c in [\"run_id\",\"vod_id\",\"user_name\",\"status\",\n","              \"step_chat\",\"step_audio\",\"step_mp4\",\"step_whisper\",\n","              \"last_update\",\"note\"]:\n","        if c in df.columns:\n","            df[c] = df[c].astype(str)\n","    # æ•°å€¤åˆ—\n","    if \"duration_seconds\" in df.columns:\n","        df[\"duration_seconds\"] = pd.to_numeric(df[\"duration_seconds\"], errors=\"coerce\").fillna(0).astype(int)\n","    if \"shard_id\" in df.columns:\n","        df[\"shard_id\"] = pd.to_numeric(df[\"shard_id\"], errors=\"coerce\").fillna(-1).astype(int)\n","    return df\n","\n","def restore_ledger_if_empty():\n","    \"\"\"\n","    ledger.csv ãŒç©º(0B)ãªã‚‰ ledger.prev.csv ã‹ã‚‰è‡ªå‹•å¾©å…ƒï¼ˆèµ·å‹•æ™‚ä¸€åº¦ã ã‘å®Ÿè¡Œï¼‰\n","    \"\"\"\n","    b = gcs_client().bucket(GCS_BUCKET)\n","    main = b.blob(LEDGER_KEY); prev = b.blob(LEDGER_BACKUP_KEY)\n","    try:\n","        if not main.exists():\n","            return\n","        main.reload()\n","        if (main.size or 0) == 0 and prev.exists():\n","            print(\"ğŸ©º ledger.csv is empty â†’ restoring from ledger.prev.csv\")\n","            prev.download_to_filename(LEDGER_BACKUP_LOCAL)\n","            main.upload_from_filename(LEDGER_BACKUP_LOCAL)\n","            print(\"âœ… restored ledger.csv\")\n","    except Exception as e:\n","        print(\"âš ï¸ ledger auto-restore failed:\", e)\n","\n","def load_ledger() -> pd.DataFrame:\n","    # æœ¬ä½“\n","    if gcs_download(LEDGER_KEY, LEDGER_LOCAL):\n","        try:\n","            if os.path.getsize(LEDGER_LOCAL) == 0:\n","                raise ValueError(\"ledger.csv is empty\")\n","            return _enforce_ledger_types(pd.read_csv(LEDGER_LOCAL))\n","        except Exception as e:\n","            print(\"âš ï¸ ledger èª­ã¿è¾¼ã¿å¤±æ•—:\", e)\n","    # æ¬¡ã« prev\n","    if gcs_download(LEDGER_BACKUP_KEY, LEDGER_BACKUP_LOCAL):\n","        try:\n","            shutil.copy2(LEDGER_BACKUP_LOCAL, LEDGER_LOCAL)\n","            return _enforce_ledger_types(pd.read_csv(LEDGER_LOCAL))\n","        except Exception as e:\n","            print(\"âš ï¸ ledger.prev èª­ã¿è¾¼ã¿å¤±æ•—:\", e)\n","    # ã©ã¡ã‚‰ã‚‚ãƒ€ãƒ¡ãªã‚‰æœ€å°ã‚«ãƒ©ãƒ ã§ç©ºDF\n","    return pd.DataFrame(columns=LEDGER_COLUMNS)\n","\n","def _ensure_ledger_columns(df: pd.DataFrame) -> pd.DataFrame:\n","    for c in LEDGER_COLUMNS:\n","        if c not in df.columns:\n","            df[c] = \"\" if c not in (\"duration_seconds\",\"shard_id\") else 0\n","    return _enforce_ledger_types(df)\n","\n","def mark_step_safe(vod_id: str, step: str, status: str, note: str = \"\", max_retries: int = 6, backoff_base: int = 2):\n","    \"\"\"\n","    ledger.csv ã‚’â€œä¸–ä»£ä¸€è‡´(CAS)â€ã§å®‰å…¨ã«æ›´æ–°ã€‚\n","    1) æœ€æ–°ä¸–ä»£ã® ledger ã‚’DL\n","    2) å½“è©²è¡Œã®ã¿ç·¨é›†\n","    3) ãƒ­ãƒ¼ã‚«ãƒ«backup\n","    4) æœ¬ä½“ã‚’ if_generation_match=<current_gen> ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆCASï¼‰\n","    5) æˆåŠŸå¾Œã« prev ã‚’æ›´æ–°\n","    ãƒ¬ãƒ¼ã‚¹æ™‚ã¯æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§å†è©¦è¡Œ\n","    \"\"\"\n","    col_map = {\"chat\":\"step_chat\",\"audio\":\"step_audio\",\"mp4\":\"step_mp4\",\"whisper\":\"step_whisper\"}\n","    col = col_map.get(step)\n","    if not col:\n","        raise ValueError(f\"unknown step: {step}\")\n","\n","    b = gcs_client().bucket(GCS_BUCKET)\n","    blob = b.blob(LEDGER_KEY)\n","\n","    attempt = 0; last_err = None\n","    while attempt < max_retries:\n","        attempt += 1\n","        try:\n","            # æœ€æ–°ä¸–ä»£\n","            blob.reload()\n","            current_gen = int(blob.generation) if blob.generation is not None else None\n","\n","            # æœ€æ–°DL\n","            blob.download_to_filename(LEDGER_LOCAL)\n","            df = _ensure_ledger_columns(pd.read_csv(LEDGER_LOCAL))\n","\n","            # è¡ŒãŒç„¡ã‘ã‚Œã°ä½œã‚‹\n","            if not (df[\"vod_id\"].astype(str) == str(vod_id)).any():\n","                new_row = {\n","                    \"run_id\":RUN_ID, \"vod_id\":str(vod_id), \"user_name\":\"\", \"duration_seconds\":0,\n","                    \"status\":\"processing\", \"step_chat\":\"pending\",\"step_audio\":\"pending\",\"step_mp4\":\"pending\",\"step_whisper\":\"pending\",\n","                    \"last_update\": jst_now_iso(), \"note\":\"\", \"shard_id\":SHARD_ID\n","                }\n","                df.loc[len(df)] = new_row\n","\n","            idx = df.index[df[\"vod_id\"].astype(str)==str(vod_id)][0]\n","            df.at[idx, col] = status\n","            if note: df.at[idx, \"note\"] = note\n","            df.at[idx, \"last_update\"] = jst_now_iso()\n","\n","            # ä¿å­˜ & ãƒ­ãƒ¼ã‚«ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—\n","            atomic_write_csv(df, LEDGER_LOCAL)\n","            shutil.copy2(LEDGER_LOCAL, LEDGER_BACKUP_LOCAL)\n","\n","            # å…ˆã«â€œæœ¬ä½“â€ï¼ˆCASï¼‰â†’ æˆåŠŸã—ãŸã‚‰ prev ã‚’æ›´æ–°\n","            if current_gen is not None:\n","                blob.upload_from_filename(LEDGER_LOCAL, if_generation_match=current_gen)\n","            else:\n","                blob.upload_from_filename(LEDGER_LOCAL)\n","            b.blob(LEDGER_BACKUP_KEY).upload_from_filename(LEDGER_BACKUP_LOCAL)\n","            return\n","        except Exception as e:\n","            last_err = e\n","            wait = backoff_base ** attempt\n","            print(f\"â†» ledger race/retry in {wait}s (attempt {attempt}/{max_retries}) ... [{vod_id}:{col}={status}] ({e})\")\n","            time.sleep(wait)\n","    print(\"âš ï¸ ledger update failed after retries:\", last_err)\n","    raise RuntimeError(f\"ledger update failed: {vod_id} {col} -> {status}\")\n","\n","# ========= Assignment =========\n","def load_assignments() -> pd.DataFrame:\n","    if gcs_download(ASSIGN_KEY, ASSIGN_LOCAL):\n","        try:\n","            return pd.read_csv(ASSIGN_LOCAL)\n","        except Exception as e:\n","            print(\"âš ï¸ assignments èª­è¾¼å¤±æ•—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯shardå‰²å½“ã‚’ä½¿ç”¨ï¼‰:\", e)\n","    return pd.DataFrame()\n","\n","# ========= TTL / Heartbeat =========\n","HEARTBEAT_SEC    = int(os.environ.get(\"HEARTBEAT_SEC\", \"60\"))     # 60s ã”ã¨ã«å¿ƒæ‹\n","STALE_LOCK_SEC   = int(os.environ.get(\"STALE_LOCK_SEC\", \"300\"))   # æ—¢å®š 5åˆ†ï¼ˆå…¨æ»…æ™‚ã®å¾©æ—§ã‚’é€Ÿãï¼‰\n","\n","WORKER_ID = f\"{socket.gethostname()}:{os.getpid()}:{uuid.uuid4().hex[:8]}\"\n","\n","class GCSLock:\n","    def __init__(self, bucket: str, key: str):\n","        self.bucket_name = bucket\n","        self.key = key\n","        self._stop = threading.Event()\n","        self._thread = None\n","\n","    def _heartbeat_loop(self):\n","        b = gcs_client().bucket(self.bucket_name); bl = b.blob(self.key)\n","        while not self._stop.wait(HEARTBEAT_SEC):\n","            try:\n","                payload = json.dumps({\"worker\": WORKER_ID, \"ts\": jst_now_iso()})\n","                bl.upload_from_string(payload)  # last-writer-wins\n","            except Exception:\n","                pass\n","\n","    def acquire(self, steal_if_stale=True) -> bool:\n","        b = gcs_client().bucket(self.bucket_name); bl = b.blob(self.key)\n","        payload = json.dumps({\"worker\": WORKER_ID, \"ts\": jst_now_iso()})\n","        # 1) æ–°è¦ä½œæˆ\n","        try:\n","            bl.upload_from_string(payload, if_generation_match=0)\n","            self._thread = threading.Thread(target=self._heartbeat_loop, daemon=True)\n","            self._thread.start()\n","            print(f\"ğŸ”’ lock acquired: gs://{self.bucket_name}/{self.key}\")\n","            return True\n","        except Exception:\n","            # 2) æ—¢å­˜ â†’ stale ãªã‚‰å¥ªå–\n","            try:\n","                bl.reload()\n","                upd = bl.updated  # datetime\n","                if upd is None:\n","                    if steal_if_stale:\n","                        bl.upload_from_string(payload)\n","                        self._thread = threading.Thread(target=self._heartbeat_loop, daemon=True)\n","                        self._thread.start()\n","                        print(f\"ğŸ”§ lock force-acquired(no-updated): {self.key}\")\n","                        return True\n","                    return False\n","                age = (datetime.now(timezone.utc) - upd).total_seconds()\n","                if steal_if_stale and age > STALE_LOCK_SEC:\n","                    meta = bl.metageneration\n","                    bl.upload_from_string(payload, if_metageneration_match=meta)\n","                    self._thread = threading.Thread(target=self._heartbeat_loop, daemon=True)\n","                    self._thread.start()\n","                    print(f\"ğŸ› ï¸ lock stolen (stale {int(age)}s): {self.key}\")\n","                    return True\n","                else:\n","                    print(f\"â›” lock busy (age {int(age)}s <= {STALE_LOCK_SEC}s): {self.key}\")\n","                    return False\n","            except Exception as e:\n","                print(f\"âš ï¸ lock check error: {e}\")\n","                return False\n","\n","    def release(self):\n","        self._stop.set()\n","        if self._thread and self._thread.is_alive():\n","            self._thread.join(timeout=3)\n","        try:\n","            b = gcs_client().bucket(self.bucket_name); bl = b.blob(self.key)\n","            if bl.exists(): bl.delete()\n","            print(f\"ğŸ”“ lock released: {self.key}\")\n","        except Exception as e:\n","            print(f\"âš ï¸ lock release error: {e}\")\n","\n","# ========= ä»»æ„ï¼šå¤ã™ãã‚‹ãƒ­ãƒƒã‚¯æƒé™¤ï¼ˆå…¨æ»…å¾Œã®å†å§‹å‹•ã‚’æ—©ã‚ã‚‹ï¼‰ =========\n","def sweep_stale_locks(multiplier: float = 2.0):\n","    \"\"\"\n","    ç’°å¢ƒå¤‰æ•° SWEEP_STALE_LOCKS=1 ã®ã¨ãã ã‘å®Ÿè¡Œã€‚\n","    TTLã® multiplier å€ã‚ˆã‚Šå¤ã„ lock ã‚’ metageneration æ¡ä»¶ä»˜ãã§å‰Šé™¤ã€‚\n","    \"\"\"\n","    if os.environ.get(\"SWEEP_STALE_LOCKS\", \"0\") != \"1\":\n","        return\n","    b = gcs_client().bucket(GCS_BUCKET)\n","    prefix = f\"{GCS_ROOT_PREFIX}/{RUN_ID}/locks/\"\n","    threshold = STALE_LOCK_SEC * multiplier\n","    for bl in b.list_blobs(prefix=prefix):\n","        try:\n","            bl.reload()\n","            upd = bl.updated\n","            if upd and (datetime.now(timezone.utc) - upd).total_seconds() > threshold:\n","                meta = bl.metageneration\n","                bl.delete(if_metageneration_match=meta)\n","                print(f\"ğŸ§¹ removed stale lock: gs://{GCS_BUCKET}/{bl.name}\")\n","        except Exception as e:\n","            print(\"âš ï¸ sweep lock error:\", e)\n","\n","# ========= DL/å¤‰æ› =========\n","def _ok_file(path, min_bytes=128) -> bool: return os.path.exists(path) and os.path.getsize(path) >= min_bytes\n","\n","def _write_log(path, text):\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","    with open(path, \"a\", encoding=\"utf-8\") as f:\n","        f.write(text if text.endswith(\"\\n\") else text + \"\\n\")\n","\n","def twitch_video_exists(vod_id: str) -> bool:\n","    try:\n","        r = requests.get(f\"{API_BASE_URL}/videos\", headers=HEADERS, params={\"id\": vod_id}, timeout=15)\n","        if r.status_code != 200: return False\n","        return len(r.json().get(\"data\", [])) > 0\n","    except Exception:\n","        return False\n","\n","CHAT_MAX_RETRY = 3\n","AUDIO_MAX_RETRY = 2\n","RETRY_BACKOFF_BASE = 2\n","\n","def chat_download(vod_id: str, out_json: str, begin: Optional[str]=None, end: Optional[str]=None, max_retry=CHAT_MAX_RETRY):\n","    log_path = os.path.join(LOG_ROOT, f\"{vod_id}_chat.log\")\n","    for attempt in range(1, max_retry+1):\n","        cmd = [TWITCHDL,\"chatdownload\",\"--id\",vod_id,\"-o\",out_json,\"--timestamp-format\",\"Relative\"]\n","        if begin: cmd += [\"-b\", begin]\n","        if end:   cmd += [\"-e\", end]\n","        t0 = time.time()\n","        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n","        out = proc.stdout or \"\"\n","        _write_log(log_path, f\"\\n--- attempt {attempt}/{max_retry} ---\\n{out}\\n(exit {proc.returncode})\\n\")\n","        ok = (proc.returncode == 0) and _ok_file(out_json)\n","        if ok:\n","            return True, f\"ok ({time.time()-t0:.1f}s)\"\n","        low = out.lower()\n","        if \"does not exist\" in low or \"404\" in low or \"private\" in low:   reason = \"not_found_or_private\"\n","        elif \"forbidden\" in low or \"unauthorized\" in low or \"403\" in low: reason = \"forbidden_or_auth\"\n","        elif \"too many requests\" in low or \"429\" in low:                  reason = \"rate_limited\"\n","        elif \"no comments\" in low:                                        reason = \"no_comments\"\n","        else:                                                              reason = \"unknown\"\n","        if attempt < max_retry: time.sleep(RETRY_BACKOFF_BASE ** attempt)\n","        else: return False, reason\n","\n","class QuietLogger:\n","    def debug(self, msg): pass\n","    def info(self, msg): pass\n","    def warning(self, msg): pass\n","    def error(self, msg): pass\n","\n","def audio_download_m4a(vod_id: str, out_m4a: str, max_retry=AUDIO_MAX_RETRY):\n","    import yt_dlp\n","    url = f\"https://www.twitch.tv/videos/{vod_id}\"\n","    ff = shutil.which(\"ffmpeg\")\n","    base_noext = out_m4a.rsplit(\".\",1)[0]\n","    # æ–­ç‰‡æƒé™¤ï¼ˆã‚¯ãƒ©ãƒƒã‚·ãƒ¥å†é–‹æ™‚ã«åŠ¹ãï¼‰\n","    for ext in (\".part\", \".ytdl\", \".temp\", \".part-Frag12.part\"):\n","        p = base_noext + ext\n","        if os.path.exists(p):\n","            try: os.remove(p)\n","            except: pass\n","\n","    for attempt in range(1, max_retry+1):\n","        t0 = time.time()\n","        pbar = None\n","        def hook(d):\n","            nonlocal pbar\n","            if d.get(\"status\") == \"downloading\":\n","                tb = d.get(\"total_bytes\") or d.get(\"total_bytes_estimate\") or 0\n","                db = d.get(\"downloaded_bytes\", 0)\n","                if pbar is None:\n","                    pbar = tqdm(total=tb if tb else None, unit=\"B\", unit_scale=True, desc=f\"audio {vod_id}\", leave=False)\n","                pbar.update(db - pbar.n)\n","            elif d.get(\"status\") == \"finished\":\n","                if pbar is not None:\n","                    pbar.total = pbar.n; pbar.close(); pbar = None\n","        opts = {\n","            \"format\":\"bestaudio/best\",\n","            \"outtmpl\": out_m4a.replace(\".m4a\",\".%(ext)s\"),\n","            \"postprocessors\":[{\"key\":\"FFmpegExtractAudio\",\"preferredcodec\":\"m4a\"}],\n","            \"ffmpeg_location\": os.path.dirname(ff) if ff else None,\n","            \"progress_hooks\":[hook],\n","            \"logger\": QuietLogger(), \"quiet\": True, \"no_warnings\": True,\n","        }\n","        log_path = os.path.join(LOG_ROOT, f\"{vod_id}_audio.log\")\n","        try:\n","            with yt_dlp.YoutubeDL(opts) as ydl:\n","                ydl.download([url])\n","        except Exception as e:\n","            _write_log(log_path, f\"[error try={attempt}] {e}\\n\")\n","            if attempt < max_retry:\n","                time.sleep(RETRY_BACKOFF_BASE ** attempt);\n","                continue\n","            else:\n","                return False, f\"error:{e}\"\n","        if _ok_file(out_m4a):\n","            return True, f\"ok ({time.time()-t0:.1f}s)\"\n","        if attempt < max_retry:\n","            time.sleep(RETRY_BACKOFF_BASE ** attempt)\n","        else:\n","            return False, \"unknown\"\n","\n","def m4a_to_mp4(m4a_path: str, mp4_path: str):\n","    t0 = time.time()\n","    cmd = [\"ffmpeg\",\"-hide_banner\",\"-nostdin\",\"-y\",\"-i\",m4a_path,\"-c\",\"copy\",mp4_path]\n","    try:\n","        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n","        return (_ok_file(mp4_path), f\"ok ({time.time()-t0:.1f}s)\")\n","    except subprocess.CalledProcessError:\n","        return False, \"ffmpeg_fail\"\n","\n","# ========= Graceful Stop (SIGINT/SIGTERM) =========\n","STOP = False\n","def _handle_stop(signum, frame):\n","    global STOP\n","    STOP = True\n","    print(f\"\\nğŸ›‘ signal {signum} å—ä¿¡: ç¾åœ¨ã®VODã‚’å®‰å…¨ã«çµ‚äº†å¾Œã€åœæ­¢ã—ã¾ã™â€¦\")\n","for _sig in (signal.SIGINT, signal.SIGTERM):\n","    try: signal.signal(_sig, _handle_stop)\n","    except Exception: pass\n","\n","# ========= èµ·å‹•æ™‚ã®è‡ªå·±ä¿®å¾©ï¼ˆledger / ãƒ­ãƒƒã‚¯ï¼‰ =========\n","restore_ledger_if_empty()\n","sweep_stale_locks()  # SWEEP_STALE_LOCKS=1 ã®ã¨ãã ã‘å‹•ã\n","\n","# ========= Assignment ãƒ­ãƒ¼ãƒ‰ =========\n","assign_df = load_assignments()\n","if assign_df.empty or \"vod_id\" not in assign_df.columns or \"shard_id\" not in assign_df.columns:\n","    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ledger ã‹ã‚‰ VOD ã‚’æ‹¾ã£ã¦ãƒãƒƒã‚·ãƒ¥ã§åˆ†æ•£\n","    led = load_ledger()\n","    if \"vod_id\" in led.columns:\n","        def _shard(v): return (hash(str(v)) % SHARD_COUNT)\n","        tmp = led[[\"vod_id\"]].dropna().copy()\n","        tmp[\"shard_id\"] = tmp[\"vod_id\"].astype(str).map(_shard)\n","        assign_df = tmp\n","    else:\n","        assign_df = pd.DataFrame(columns=[\"vod_id\",\"shard_id\"])\n","\n","my_vods = assign_df.loc[assign_df[\"shard_id\"]==SHARD_ID, \"vod_id\"].astype(str).unique().tolist()\n","print(f\"ğŸ”¢ SHARD {SHARD_ID}: æ‹…å½“ {len(my_vods)} ä»¶\")\n","\n","# ========= ãƒ¡ã‚¤ãƒ³: å„VODã‚’å·¥ç¨‹ã”ã¨ã«å®‰å…¨å‡¦ç† =========\n","ledger = load_ledger()\n","if not ledger.empty:\n","    ledger = _ensure_ledger_columns(ledger)\n","\n","if ledger.empty or \"vod_id\" not in ledger.columns:\n","    print(\"âš ï¸ ledger ãŒç©ºã§ã™ã€‚äº‹å‰ã«åé›†å´ã§ ledger ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„ã€‚\")\n","    target_vods = my_vods\n","else:\n","    # ã“ã® shard ãŒæ‹…å½“ã®è¡Œã«é™å®š\n","    target_rows = ledger[ledger[\"vod_id\"].astype(str).isin(my_vods)].copy()\n","    mask_done = (target_rows[\"step_chat\"]==\"ok\") & (target_rows[\"step_audio\"]==\"ok\") & (target_rows[\"step_mp4\"]==\"ok\")\n","    to_process = target_rows[~mask_done].copy()\n","    target_vods = to_process[\"vod_id\"].astype(str).tolist()\n","\n","print(f\"ğŸ—‚ï¸ å‡¦ç†äºˆå®š: {len(target_vods)} / æ‹…å½“ {len(my_vods)} ä»¶ï¼ˆSHARD {SHARD_ID}ï¼‰\")\n","\n","vod_iter = tqdm(target_vods, total=len(target_vods), unit=\"vod\", desc=f\"SHARD {SHARD_ID} processing\")\n","for vod_id in vod_iter:\n","    if STOP: break\n","\n","    lock_key = f\"{LOCK_PREFIX}/{vod_id}.lock\"\n","    lock = GCSLock(GCS_BUCKET, lock_key)\n","    if not lock.acquire(steal_if_stale=True):\n","        # ä»–ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒå‡¦ç†ä¸­\n","        continue\n","\n","    step_bar = tqdm(total=3, desc=f\"{vod_id} steps\", unit=\"step\", leave=False)\n","    try:\n","        # ç”Ÿå­˜ç¢ºèªï¼ˆæ¶ˆå»/éå…¬é–‹ï¼‰\n","        if not twitch_video_exists(vod_id):\n","            print(f\"ğŸ“¼ VOD {vod_id} | âŒ not found/private\")\n","            try:\n","                mark_step_safe(vod_id, \"chat\",  \"fail\", \"video_not_found\")\n","                mark_step_safe(vod_id, \"audio\", \"fail\", \"video_not_found\")\n","                mark_step_safe(vod_id, \"mp4\",   \"fail\", \"video_not_found\")\n","            finally:\n","                step_bar.update(3)\n","            continue\n","\n","        chat_path = os.path.join(TMP_DIR, f\"{vod_id}_chat.json\")\n","        m4a_path  = os.path.join(TMP_DIR, f\"{vod_id}.m4a\")\n","        mp4_path  = os.path.join(TMP_DIR, f\"{vod_id}.mp4\")\n","\n","        # --- chat ---\n","        cur = load_ledger()\n","        step_chat = \"pending\"\n","        if not cur.empty and \"vod_id\" in cur.columns and \"step_chat\" in cur.columns:\n","            row = cur[cur[\"vod_id\"].astype(str)==vod_id]\n","            if not row.empty:\n","                step_chat = str(row[\"step_chat\"].iloc[0] or \"pending\")\n","        if step_chat != \"ok\":\n","            ok_chat, chat_note = chat_download(vod_id, chat_path)\n","            if ok_chat:\n","                up_ok = gcs_upload(chat_path, gcs_key(\"raw/chat\", f\"{vod_id}_chat.json\"), content_type=\"application/json\")\n","                if up_ok:\n","                    _safe_remove(chat_path)  # âœ… å³å‰Šé™¤\n","                    mark_step_safe(vod_id, \"chat\", \"ok\", chat_note)\n","                else:\n","                    mark_step_safe(vod_id, \"chat\", \"fail\", \"gcs_upload_failed\")\n","            else:\n","                mark_step_safe(vod_id, \"chat\", \"fail\", chat_note)\n","        step_bar.update(1)\n","\n","        # --- audio ---\n","        cur = load_ledger()\n","        step_audio = \"pending\"\n","        if not cur.empty and \"vod_id\" in cur.columns and \"step_audio\" in cur.columns:\n","            row = cur[cur[\"vod_id\"].astype(str)==vod_id]\n","            if not row.empty:\n","                step_audio = str(row[\"step_audio\"].iloc[0] or \"pending\")\n","        if step_audio != \"ok\":\n","            ok_audio, audio_note = audio_download_m4a(vod_id, m4a_path)\n","            if ok_audio:\n","                up_ok = gcs_upload(m4a_path, gcs_key(\"raw/audio\", f\"{vod_id}.m4a\"), content_type=\"audio/mp4\")\n","                if up_ok:\n","                    # mp4 å¤‰æ›ã§ä½¿ã†ãŸã‚ã“ã“ã§ã¯å‰Šé™¤ã—ãªã„\n","                    mark_step_safe(vod_id, \"audio\", \"ok\", audio_note)\n","                else:\n","                    mark_step_safe(vod_id, \"audio\", \"fail\", \"gcs_upload_failed\")\n","            else:\n","                mark_step_safe(vod_id, \"audio\", \"fail\", audio_note)\n","        step_bar.update(1)\n","\n","        # --- mp4 ---\n","        cur = load_ledger()\n","        step_mp4 = \"pending\"\n","        if not cur.empty and \"vod_id\" in cur.columns and \"step_mp4\" in cur.columns:\n","            row = cur[cur[\"vod_id\"].astype(str)==vod_id]\n","            if not row.empty:\n","                step_mp4 = str(row[\"step_mp4\"].iloc[0] or \"pending\")\n","        if step_mp4 != \"ok\":\n","            if _ok_file(m4a_path):\n","                ok_mp4, mp4_note = m4a_to_mp4(m4a_path, mp4_path)\n","                if ok_mp4 and _ok_file(mp4_path):\n","                    up_ok = gcs_upload(mp4_path, gcs_key(\"processed/audio_mp4\", f\"{vod_id}.mp4\"), content_type=\"video/mp4\")\n","                    if up_ok:\n","                        _safe_remove(mp4_path)  # âœ… mp4ã¯å³å‰Šé™¤\n","                        _safe_remove(m4a_path)  # âœ… mp4ç”Ÿæˆå¾Œã¯m4aã‚‚å‰Šé™¤\n","                        mark_step_safe(vod_id, \"mp4\", \"ok\", mp4_note)\n","                    else:\n","                        mark_step_safe(vod_id, \"mp4\", \"fail\", \"gcs_upload_failed\")\n","                else:\n","                    mark_step_safe(vod_id, \"mp4\", \"fail\", mp4_note)\n","            else:\n","                mark_step_safe(vod_id, \"mp4\", \"fail\", \"no_m4a\")\n","        step_bar.update(1)\n","\n","    except Exception as e:\n","        print(f\"âš ï¸ unexpected error in {vod_id}: {e}\")\n","    finally:\n","        step_bar.close()\n","        # å¯èƒ½ãªæ®‹éª¸ã®æƒé™¤ï¼ˆ.partç­‰ï¼‰\n","        for p in pathlib.Path(TMP_DIR).glob(f\"{vod_id}*\"):\n","            try:\n","                if p.is_file():\n","                    p.unlink()\n","            except Exception:\n","                pass\n","        lock.release()\n","\n","print(\"ğŸ‰ worker å®Œäº† (v2 daily)\")\n","\n","# =========================\n","# ä½¿ã„æ–¹ãƒ¡ãƒ¢:\n","# - ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ledger.csv ãŒç©ºã§ã‚‚è‡ªå‹•ã§ .prev ã‹ã‚‰å¾©æ—§ã—ã¾ã™ï¼ˆèµ·å‹•æ™‚ï¼‰ã€‚\n","# - å°å¸³æ›´æ–°ã¯ã€Œæœ¬ä½“(CAS)â†’æˆåŠŸå¾Œã« .prevã€é †ã€‚â€œ.prevã ã‘å…ˆè¡Œï¼æœ¬ä½“ãŒç©ºâ€ã®ä¸æ•´åˆã‚’é˜²ãã¾ã™ã€‚\n","# - TTLã¯æ—¢å®š5åˆ†ï¼ˆHEARTBEAT=60sï¼‰ã€‚ã‚¯ãƒ©ãƒƒã‚·ãƒ¥å¾Œã¯5åˆ†çµŒéã§åˆ¥ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒè‡ªå‹•å¼•ãç¶™ãã€‚\n","# - å…¨æ»…å¾Œã®å†èµ·å‹•ã§ stale lock ã‚’æ—©æœŸå›åã—ãŸã„ã¨ãã¯ SWEEP_STALE_LOCKS=1 ã‚’æŒ‡å®šã—ã¦èµ·å‹•ã€‚\n","# =========================\n"]}]}