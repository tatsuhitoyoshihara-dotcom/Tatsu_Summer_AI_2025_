{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNsXHFVlYkQbsuDNmetJ+jP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2d-kFeyLy-zT"},"outputs":[],"source":["# ==============================================\n","# Twitch LLM QA Experiment (Resume-safe, 1-cell)\n","#  - NUM_LIVE==1 の時は、EXCLUDE_LIVE_IDS を避けてランダムで1件選択\n","#  - MCQ生成: 古いプロンプト（そのまま）\n","#  - 回答: 新しいプロンプト（具体的な数値例を出さない）\n","#  - 選択肢シャッフル: 安定乱数で permute（GTも更新）\n","#  - 進捗: tqdm\n","#  - 保存: Local + GCS（レジューム可：既存があればスキップ）\n","#  - 追加: 各ステージの pred_index 分布を表示\n","# ==============================================\n","\n","from __future__ import annotations\n","import os, io, re, json, textwrap, datetime, hashlib, time, random\n","from typing import Dict, Any, List, Tuple, Optional\n","\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","\n","import fsspec\n","import vertexai\n","from vertexai.generative_models import GenerativeModel, GenerationConfig\n","\n","# ====================== CONFIG（ここを調整） ======================\n","PROJECT_ID           = \"dena-ai-intern-ds-dev-gcp\"\n","LOCATION             = \"us-central1\"\n","MODEL_NAME           = \"gemini-2.5-pro\"\n","TEMPERATURE          = 0\n","\n","# ---- 入力（Twitch ペアCSV、RUN_IDごとに固定）----\n","RUN_ID               = \"20250910_190657\"  # ★あなたの Twitch RUN_ID を入れる\n","PAIRS_CSV_PATH       = f\"gs://dena-ai-intern-yoshihara-data/yoshi_LLMQA_twitch_pairs/llmqa_pairs_{RUN_ID}.csv\"\n","\n","# ---- 対象ライブ（VOD）選択 ----\n","NUM_LIVE             = 15\n","LIVE_IDS_EXPLICIT: List[str] = []         # 明示指定するなら [\"2562056128\"] のように。空なら自動選択\n","RANDOM_ONE_IF_SINGLE = True               # NUM_LIVE==1 かつ LIVE_IDS_EXPLICIT が空ならランダム抽出\n","EXCLUDE_LIVE_IDS     = [\"2561384383\"]     # ★重かった ID をここに列挙（複数可）\n","\n","# ---- フィルタ・その他 ----\n","MIN_COMBINED_CHARS   = 500                # combined が短すぎるチャンクはスキップ\n","RNG_SEED_BASE        = 20240917           # 安定シャッフルのベースシード\n","CHECKPOINT_EVERY     = 100                # 進捗CSVの保存間隔\n","\n","# ---- 出力（新規パス。Local & GCS に同構造で保存）----\n","GCS_BASE_PREFIX      = \"gs://dena-ai-intern-yoshihara-data/yoshi_LLMQA_twitch_runs\"\n","RESUME_RUN_LABEL     = \"\"                 # 既存ラベル指定で再開。空なら自動生成\n","RUN_LABEL            = \"\"                 # 明示指定したい場合のみ\n","# ===============================================================\n","\n","\n","# ====================== Helpers (FS / Model / JSON / Paths) ======================\n","def _dedent(s: str) -> str:\n","    return textwrap.dedent(s).strip()\n","\n","def fs_gcs():\n","    return fsspec.filesystem(\"gcs\")\n","\n","def read_gcs_text(path: str) -> str:\n","    fs = fs_gcs()\n","    with fs.open(path, \"r\") as f:\n","        return f.read()\n","\n","def write_gcs_text(path: str, text: str) -> None:\n","    fs = fs_gcs()\n","    with fs.open(path, \"w\") as f:\n","        f.write(text)\n","\n","def gcs_exists(path: str) -> bool:\n","    fs = fs_gcs()\n","    try:\n","        return fs.exists(path)\n","    except Exception:\n","        return False\n","\n","def gcs_glob(prefix: str, pattern: str=\"**\") -> List[str]:\n","    fs = fs_gcs()\n","    try:\n","        return sorted(fs.glob(f\"{prefix}/{pattern}\"))\n","    except Exception:\n","        return []\n","\n","def init_vertex_ai(model_name: str) -> GenerativeModel:\n","    vertexai.init(project=PROJECT_ID, location=LOCATION)\n","    return GenerativeModel(model_name)\n","\n","def call_model_return_both(model: GenerativeModel, content: str) -> Tuple[Dict[str, Any], str]:\n","    cfg = GenerationConfig(temperature=TEMPERATURE)\n","    raw = \"\"\n","    try:\n","        resp = model.generate_content([content], generation_config=cfg)\n","        try:\n","            raw = resp.text or \"\"\n","        except Exception:\n","            raw = \"\"\n","    except Exception:\n","        raw = \"\"\n","    # robust JSON\n","    def robust_json_loads(text: str) -> Optional[Dict[str, Any]]:\n","        try:\n","            return json.loads(text)\n","        except Exception:\n","            pass\n","        m = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", text, flags=re.DOTALL)\n","        if m:\n","            try:\n","                return json.loads(m.group(1))\n","            except Exception:\n","                pass\n","        m = re.search(r\"(\\{.*\\})\", text, flags=re.DOTALL)\n","        if m:\n","            s = m.group(1)\n","            s = s[: s.rfind(\"}\") + 1]\n","            try:\n","                return json.loads(s)\n","            except Exception:\n","                pass\n","        return None\n","    obj = robust_json_loads(raw) or {\"raw_text\": raw}\n","    return obj, raw\n","\n","def local_base_dir() -> str:\n","    return os.path.join(\"llmqa_twitch_runs\", RUN_LABEL)\n","\n","def gcs_base_prefix() -> str:\n","    return f\"{GCS_BASE_PREFIX}/{RUN_LABEL}\"\n","\n","def ensure_local_dir(path: str) -> None:\n","    os.makedirs(path, exist_ok=True)\n","\n","def write_local_text(path: str, text: str) -> None:\n","    ensure_local_dir(os.path.dirname(path))\n","    with open(path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(text)\n","\n","def write_local_json(path: str, obj: Any) -> None:\n","    write_local_text(path, json.dumps(obj, ensure_ascii=False, indent=2))\n","\n","def write_both_text(rel_path: str, text: str) -> None:\n","    lpath = os.path.join(local_base_dir(), rel_path)\n","    write_local_text(lpath, text)\n","    gpath = f\"{gcs_base_prefix()}/{rel_path}\"\n","    try:\n","        write_gcs_text(gpath, text)\n","    except Exception:\n","        pass\n","\n","def write_both_json(rel_path: str, obj: Any) -> None:\n","    write_both_text(rel_path, json.dumps(obj, ensure_ascii=False, indent=2))\n","\n","def exists_local(rel_path: str) -> bool:\n","    return os.path.exists(os.path.join(local_base_dir(), rel_path))\n","\n","def exists_gcs(rel_path: str) -> bool:\n","    return gcs_exists(f\"{gcs_base_prefix()}/{rel_path}\")\n","\n","def exists_any(rel_path: str) -> bool:\n","    return exists_local(rel_path) or exists_gcs(rel_path)\n","\n","def read_local_json(rel_path: str) -> Optional[Any]:\n","    path = os.path.join(local_base_dir(), rel_path)\n","    try:\n","        with open(path, \"r\", encoding=\"utf-8\") as f:\n","            return json.load(f)\n","    except Exception:\n","        return None\n","\n","def read_gcs_json(rel_path: str) -> Optional[Any]:\n","    path = f\"{gcs_base_prefix()}/{rel_path}\"\n","    try:\n","        return json.loads(read_gcs_text(path))\n","    except Exception:\n","        return None\n","\n","def read_any_json(rel_path: str) -> Optional[Any]:\n","    return read_local_json(rel_path) or read_gcs_json(rel_path)\n","\n","\n","# ====================== Prompts ======================\n","def prompt_for_mcq_fixed() -> str:\n","    # ★問題作成プロンプトは「古い版」をそのまま使う（例で answer_index:0 を含む）\n","    return _dedent(\"\"\"\n","        以下の『配信ログ本文』だけを根拠に、ライブ配信に関する4択問題を日本語で作成してください。外部知識の持ち込みは禁止です。\n","\n","        # 出題ルール（厳守）\n","        - 問題数: 2 問（ちょうど2問。増減しない）\n","        - 1問目は、次の固定文言をそのまま問題文に使う：\n","          『配信中に出てきた話題は、以下の四つの選択肢のうちどれが正しいですか？』\n","        - 2問目は、次のテンプレートの {TOPIC} を 1問目の正解選択肢のテキスト（短い名詞句）に置換して使う：\n","          『配信中、{TOPIC}に関して行われた会話の内容は、以下のどれか？』\n","          ※ 出力時に {TOPIC} を残さないこと。\n","        - 似た選択肢は作らない。正解は各問ちょうど1つ。\n","        - あいまい表現や主観的解釈は禁止。本文の根拠のみ。\n","        - 挨拶など普遍的な内容は題材にしない。\n","        - 出力は JSON のみ。説明文やコードフェンス（```）は禁止。\n","        - 以下に与えた具体的な例とは異なる問題と選択肢を作成する。\n","        - 配信者/リスナーの区別や経過時間を問題文に含めない。\n","        - 説明(explanation)はRecitation回避のため原文の直接引用禁止。根拠は短い要約（100文字以内）。\n","        - 配信ログ本文を読んだら、必ず正解が選べるような問題を作ってください。\n","\n","        # 出力フォーマット（厳守）\n","        {\n","          \"questions\": [\n","            {\n","              \"question\": \"配信中に出てきた話題は、以下の四つの選択肢のうちどれが正しいですか？\",\n","              \"choices\": [\"選択肢A\", \"選択肢B\", \"選択肢C\", \"選択肢D\"],\n","              \"answer_index\": 0,\n","              \"explanation\": \"本文からの根拠（直接引用）\"\n","            },\n","            {\n","              \"question\": \"配信中、{TOPIC}に関して行われた会話の内容は、以下のどれか？\",\n","              \"choices\": [\"選択肢A\", \"選択肢B\", \"選択肢C\", \"選択肢D\"],\n","              \"answer_index\": 0,\n","              \"explanation\": \"本文からの根拠\"\n","            }\n","          ]\n","        }\n","\n","        # 例（one-shot）\n","        一つ目の問い\n","        問題文：配信中に出てきた話題は、以下の四つの選択肢のうちどれが正しいですか？\n","        選択肢A：唐揚げ\n","        選択肢B：不動産投資\n","        選択肢C：大阪の万博\n","        選択肢D：オーストラリアでのマラソン\n","        正解のインデックス：0\n","\n","        二つ目の問い\n","        問題文：配信中、{TOPIC}に関して行われた会話の内容は、以下のどれか？\n","        選択肢A：唐揚げはもも肉より胸肉の方が良い\n","        選択肢B：唐揚げの値上げが嫌だ\n","        選択肢C：いつも唐揚げ食べると胃もたれする\n","        選択肢D：唐揚げにはレモンをかけるべきか否か\n","        正解のインデックス：3\n","\n","        # 配信ログ本文\n","    \"\"\")\n","\n","def prompt_for_answering(qname: str, source_label: str) -> str:\n","    # ★新しい版：0の具体例を見せない（プレースホルダだけ）\n","    return _dedent(f\"\"\"\n","        次の『{source_label}だけ』を根拠に、与えられた1問({qname})の4択に回答してください。\n","        - 出力は JSON のみ（コードフェンス禁止）。\n","        - 回答は 0..3 の整数インデックス（choices 配列の添字）。\n","        - {{0から3までの数値}}の部分はLLMの回答の数値で置き換えてください。\n","\n","        # 出力フォーマット\n","        {{\n","          \"answers\": {{\n","            \"{qname.lower()}_index\": {{0から3までの数値を入れてください}}\n","          }}\n","        }}\n","\n","        # {qname}（question & choices のみ）\n","        # この後に {qname} のJSONを貼ります（answer_index/explanation は含みません）。\n","\n","        # 本文\n","    \"\"\")\n","\n","# ====================== Pairs CSV & Task building ======================\n","def load_pairs_df() -> pd.DataFrame:\n","    txt = read_gcs_text(PAIRS_CSV_PATH)\n","    df = pd.read_csv(io.StringIO(txt))\n","    # 期待列: vod_id, chunk_idx, combined_path, chatonly_path\n","    need = {\"vod_id\",\"chunk_idx\",\"combined_path\",\"chatonly_path\"}\n","    miss = [c for c in need if c not in df.columns]\n","    if miss:\n","        raise ValueError(f\"pairs CSV missing columns: {miss}\")\n","    df[\"vod_id\"] = df[\"vod_id\"].astype(str)\n","    df[\"chunk_idx\"] = pd.to_numeric(df[\"chunk_idx\"], errors=\"coerce\").astype(int)\n","    return df\n","\n","def select_live_ids(df_pairs: pd.DataFrame, k: int) -> List[str]:\n","    # 1) 明示指定があればそれを優先\n","    if LIVE_IDS_EXPLICIT:\n","        uniq = []\n","        seen = set()\n","        all_ids = set(df_pairs[\"vod_id\"].astype(str))\n","        for v in LIVE_IDS_EXPLICIT:\n","            if v in all_ids and v not in seen:\n","                uniq.append(v); seen.add(v)\n","            if len(uniq) >= k: break\n","        return uniq\n","\n","    # 2) NUM_LIVE==1 かつ RANDOM_ONE_IF_SINGLE の場合、EXCLUDE_LIVE_IDS を除いてランダム抽出\n","    if k == 1 and RANDOM_ONE_IF_SINGLE:\n","        uniq_all = []\n","        seen = set()\n","        for v in df_pairs[\"vod_id\"].astype(str).tolist():\n","            if v not in seen:\n","                seen.add(v); uniq_all.append(v)\n","        candidates = [v for v in uniq_all if v not in set(EXCLUDE_LIVE_IDS)]\n","        if not candidates:\n","            candidates = uniq_all  # さすがに空は避ける\n","        # 時刻ベースの乱数で選択（毎回変わる）\n","        random.seed(int(time.time()))\n","        choice = random.choice(candidates)\n","        print(f\"[select_live_ids] RANDOM pick (excluding {EXCLUDE_LIVE_IDS}): {choice}\")\n","        return [choice]\n","\n","    # 3) それ以外は先頭から順に k 件\n","    uniq = []\n","    seen = set()\n","    for v in df_pairs[\"vod_id\"].astype(str).tolist():\n","        if v not in seen:\n","            uniq.append(v); seen.add(v)\n","        if len(uniq) >= k: break\n","    return uniq\n","\n","def make_run_label() -> str:\n","    now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    n = len(LIVE_IDS_EXPLICIT) if LIVE_IDS_EXPLICIT else NUM_LIVE\n","    return f\"run_{RUN_ID}_{n}lives_{now}\"\n","\n","# ====================== MCQ生成（古いプロンプト） ======================\n","def generate_mcq_for_chunk(model: GenerativeModel, combined_text: str, save_label: str) -> Optional[Dict[str,Any]]:\n","    prompt = prompt_for_mcq_fixed()\n","    content = prompt + \"\\n\" + (combined_text or \"\")\n","    obj, raw = call_model_return_both(model, content)\n","    # sanitize: 確実に2問に揃え、Q2の{TOPIC}置換\n","    def ensure_two_questions(mcq: Dict[str,Any]) -> Dict[str,Any]:\n","        if isinstance(mcq, dict) and isinstance(mcq.get(\"questions\"), list):\n","            if len(mcq[\"questions\"]) > 2:\n","                mcq[\"questions\"] = mcq[\"questions\"][:2]\n","        return mcq\n","    def fill_topic(mcq: Dict[str,Any]) -> Optional[Dict[str,Any]]:\n","        if not isinstance(mcq, dict) or \"questions\" not in mcq: return None\n","        qs = mcq.get(\"questions\") or []\n","        if len(qs) < 2: return None\n","        try:\n","            aidx = int(qs[0].get(\"answer_index\", 0))\n","            topic = (qs[0].get(\"choices\") or [])[aidx]\n","        except Exception:\n","            return None\n","        if not isinstance(topic, str) or not topic.strip(): return None\n","        q2q = str(qs[1].get(\"question\",\"\"))\n","        for ph in (\"{TOPIC}\", \"<Q1正解>\", \"{一つ目の問の答え}\"):\n","            q2q = q2q.replace(ph, topic)\n","        qs[1][\"question\"] = q2q\n","        mcq[\"questions\"] = qs[:2]\n","        return mcq\n","    obj = ensure_two_questions(obj)\n","    obj = fill_topic(obj) or obj\n","    # 最低限の妥当性\n","    try:\n","        qs = obj[\"questions\"]\n","        assert isinstance(qs, list) and len(qs) == 2\n","        for q in qs:\n","            assert isinstance(q.get(\"question\",\"\"), str)\n","            assert isinstance(q.get(\"choices\", []), list) and len(q[\"choices\"]) == 4\n","            int(q.get(\"answer_index\", 0))  # int化できる\n","    except Exception:\n","        return {\"raw_text\": raw}  # ログには残す\n","    return obj\n","\n","def q_full_path(lid: str, idx: int) -> str:\n","    return f\"questions/full/{lid}_{idx}.json\"\n","def q_pub_path(lid: str, idx: int) -> str:\n","    return f\"questions/public/{lid}_{idx}.json\"\n","\n","# ====================== Distributions ======================\n","def gt_distribution_from_full(paths: List[str]) -> Dict[str, Dict[int,float]]:\n","    cnt = {\"Q1\":[0,0,0,0], \"Q2\":[0,0,0,0]}\n","    tot = {\"Q1\":0, \"Q2\":0}\n","    for rel in paths:\n","        mcq = read_any_json(rel)\n","        if not (isinstance(mcq, dict) and \"questions\" in mcq and isinstance(mcq[\"questions\"], list) and len(mcq[\"questions\"])==2):\n","            continue\n","        try:\n","            a1 = int(mcq[\"questions\"][0][\"answer_index\"]); cnt[\"Q1\"][a1]+=1; tot[\"Q1\"]+=1\n","            a2 = int(mcq[\"questions\"][1][\"answer_index\"]); cnt[\"Q2\"][a2]+=1; tot[\"Q2\"]+=1\n","        except Exception:\n","            continue\n","    out = {}\n","    for k in [\"Q1\",\"Q2\"]:\n","        t = max(1, tot[k])\n","        out[k] = {i: float(cnt[k][i])/t for i in range(4)}\n","    return out\n","\n","def gt_distribution_from_shuffled(keys: List[str]) -> Dict[str, Dict[int,float]]:\n","    cnt = {\"Q1\":[0,0,0,0], \"Q2\":[0,0,0,0]}\n","    tot = {\"Q1\":0, \"Q2\":0}\n","    for key in keys:\n","        rel = f\"shuffled/by_key/{key}.json\"\n","        rec = read_any_json(rel)\n","        if not isinstance(rec, dict): continue\n","        qn = rec.get(\"qname\")\n","        gi = rec.get(\"new_gt_index\")\n","        if qn in (\"Q1\",\"Q2\") and isinstance(gi, int) and 0<=gi<4:\n","            cnt[qn][gi]+=1; tot[qn]+=1\n","    out = {}\n","    for k in [\"Q1\",\"Q2\"]:\n","        t = max(1, tot[k])\n","        out[k] = {i: float(cnt[k][i])/t for i in range(4)}\n","    return out\n","\n","# ====================== Shuffle (stable) ======================\n","def key_tuple_str(lid: str, chunk_idx: int, qname: str) -> str:\n","    return f\"{lid}_{chunk_idx}_{qname}\"\n","\n","def seed_for_item(base_seed: int, lid: str, chunk_idx: int, qname: str) -> int:\n","    h = hashlib.blake2b(digest_size=8)\n","    h.update(f\"{base_seed}|{lid}|{chunk_idx}|{qname}\".encode(\"utf-8\"))\n","    return int.from_bytes(h.digest(), \"little\", signed=False)\n","\n","def stable_shuffle(choices: List[str], gt_index: int, lid: str, chunk_idx: int, qname: str) -> Tuple[List[str], int, List[int]]:\n","    rng = np.random.default_rng(seed_for_item(RNG_SEED_BASE, lid, chunk_idx, qname))\n","    perm = rng.permutation(4)\n","    new_choices = [choices[old] for old in perm]\n","    new_gt = int(np.where(perm == gt_index)[0][0])\n","    assert new_choices[new_gt] == choices[gt_index]\n","    return new_choices, new_gt, perm.tolist()\n","\n","def get_or_make_shuffle_record(lid: str, chunk_idx: int, qname: str, qjson_full: Dict[str,Any]) -> Dict[str,Any]:\n","    key = key_tuple_str(lid, chunk_idx, qname)\n","    rel = f\"shuffled/by_key/{key}.json\"\n","    rec = read_any_json(rel)\n","    if rec is not None:\n","        return rec\n","    q = qjson_full[\"questions\"][0] if qname==\"Q1\" else qjson_full[\"questions\"][1]\n","    new_choices, new_gt, perm = stable_shuffle(q[\"choices\"], int(q[\"answer_index\"]), lid, chunk_idx, qname)\n","    rec = {\n","        \"key\": key,\n","        \"live_id\": lid,\n","        \"chunk_idx\": chunk_idx,\n","        \"qname\": qname,\n","        \"question\": q[\"question\"],\n","        \"orig_choices\": q[\"choices\"],\n","        \"new_choices\": new_choices,\n","        \"orig_gt_index\": int(q[\"answer_index\"]),\n","        \"new_gt_index\": int(new_gt),\n","        \"perm_new_to_old\": perm,\n","    }\n","    write_both_json(rel, rec)\n","    return rec\n","\n","# ====================== Answering ======================\n","def build_answer_content(qname: str, source_label: str, qjson_public: Dict[str, Any], body_text: Optional[str]) -> str:\n","    prompt = prompt_for_answering(qname, source_label)\n","    base = f\"\"\"{prompt}\n","\n","# {qname} JSON\n","{json.dumps(qjson_public, ensure_ascii=False, indent=2)}\n","\"\"\"\n","    if body_text and body_text.strip():\n","        return base + f\"\\n# 本文\\n{body_text}\"\n","    else:\n","        return base\n","\n","def parse_pred_index(obj: Dict[str, Any], qname: str) -> Tuple[Optional[int], int]:\n","    if not isinstance(obj, dict): return (None,1)\n","    ans = obj.get(\"answers\", {})\n","    if not isinstance(ans, dict): return (None,1)\n","    key = f\"{qname.lower()}_index\"\n","    val = ans.get(key, ans.get(\"index\"))\n","    try:\n","        pred = int(val)\n","    except Exception:\n","        return (None,1)\n","    if 0 <= pred <= 3:\n","        return (pred,0)\n","    return (None,1)\n","\n","def stage_answer(model: GenerativeModel, tasks: List[Dict[str, Any]],\n","                 stage_code: str, source_label: str, include_body: bool) -> List[Dict[str, Any]]:\n","    new_logs = []\n","    pbar = tqdm(total=len(tasks), desc=f\"{stage_code}: 0/{len(tasks)}\", dynamic_ncols=True)\n","    done = 0\n","    for t in tasks:\n","        key = key_tuple_str(t[\"lid\"], t[\"chunk_idx\"], t[\"qname\"])\n","        log_rel = f\"logs/{stage_code}/by_key/{key}.json\"\n","        if exists_any(log_rel):\n","            done += 1; pbar.set_description_str(f\"{stage_code}: {done}/{len(tasks)}\"); pbar.update(1)\n","            continue\n","\n","        sh = read_any_json(f\"shuffled/by_key/{key}.json\")\n","        if not isinstance(sh, dict):\n","            done += 1; pbar.set_description_str(f\"{stage_code}: {done}/{len(tasks)}\"); pbar.update(1)\n","            continue\n","\n","        q_pub = {\"question\": sh[\"question\"], \"choices\": sh[\"new_choices\"]}\n","        body = \"\"\n","        if include_body:\n","            if \"combined\" in stage_code.lower():\n","                body = t.get(\"combined_text\",\"\") or \"\"\n","                if not body and isinstance(t.get(\"combined_path\"), str):\n","                    try: body = read_gcs_text(t[\"combined_path\"])\n","                    except Exception: body = \"\"\n","            elif \"chat\" in stage_code.lower():\n","                body = t.get(\"chat_text\",\"\") or \"\"\n","                if not body and isinstance(t.get(\"chat_path\"), str):\n","                    try: body = read_gcs_text(t[\"chat_path\"])\n","                    except Exception: body = \"\"\n","\n","        content = build_answer_content(t[\"qname\"], source_label, q_pub, body_text=body)\n","        obj, raw = call_model_return_both(model, content)\n","        pred, invalid = parse_pred_index(obj, t[\"qname\"])\n","        correct = int(pred == int(sh[\"new_gt_index\"])) if (invalid==0 and pred is not None) else None\n","\n","        log_rec = {\n","            \"key\": key,\n","            \"stage\": stage_code,\n","            \"live_id\": t[\"lid\"],\n","            \"chunk_idx\": t[\"chunk_idx\"],\n","            \"qname\": t[\"qname\"],\n","            \"source_label\": source_label,\n","            \"include_body\": bool(include_body),\n","            \"question\": sh[\"question\"],\n","            \"choices\": sh[\"new_choices\"],\n","            \"new_gt_index\": int(sh[\"new_gt_index\"]),\n","            \"pred_index\": (int(pred) if pred is not None else None),\n","            \"invalid_format\": int(invalid),\n","            \"correct\": (int(correct) if correct is not None else None),\n","            \"prompt_sent\": content,\n","            \"raw_response\": raw,\n","            \"ts\": datetime.datetime.now().isoformat(timespec=\"seconds\"),\n","        }\n","        write_both_json(log_rel, log_rec)\n","        new_logs.append(log_rec)\n","\n","        done += 1\n","        pbar.set_description_str(f\"{stage_code}: {done}/{len(tasks)}\")\n","        pbar.update(1)\n","    pbar.close()\n","    return new_logs\n","\n","def load_stage_logs(stage_code: str) -> pd.DataFrame:\n","    recs = []\n","    # local\n","    base = os.path.join(local_base_dir(), f\"logs/{stage_code}/by_key\")\n","    if os.path.isdir(base):\n","        for fn in os.listdir(base):\n","            if fn.endswith(\".json\"):\n","                try:\n","                    with open(os.path.join(base, fn), \"r\", encoding=\"utf-8\") as f:\n","                        recs.append(json.load(f))\n","                except Exception:\n","                    pass\n","    # gcs\n","    for gp in gcs_glob(f\"{gcs_base_prefix()}/logs/{stage_code}/by_key\", pattern=\"*.json\"):\n","        key = os.path.basename(gp).replace(\".json\",\"\")\n","        if any(r.get(\"key\")==key for r in recs):\n","            continue\n","        try:\n","            txt = read_gcs_text(gp)\n","            recs.append(json.loads(txt))\n","        except Exception:\n","            pass\n","    cols = [\"key\",\"stage\",\"live_id\",\"chunk_idx\",\"qname\",\"new_gt_index\",\"pred_index\",\"invalid_format\",\"correct\"]\n","    return pd.DataFrame(recs)[cols] if recs else pd.DataFrame(columns=cols)\n","\n","# ====================== Samples (correct/incorrect 各2件をローカル保存) ======================\n","def save_stage_samples(stage_code: str, k_each: int = 2) -> None:\n","    df = load_stage_logs(stage_code)\n","    for cls, cond in [(\"correct\", df[\"correct\"]==1),\n","                      (\"incorrect\", df[\"correct\"]==0)]:\n","        sub = df[cond].head(k_each)\n","        for _, r in sub.iterrows():\n","            key = r[\"key\"]\n","            rel = f\"logs/{stage_code}/by_key/{key}.json\"\n","            log = read_any_json(rel) or {}\n","            lines = []\n","            lines.append(f\"### META\\nstage: {stage_code}\\nkey: {key}\\nlive_id: {r['live_id']}\\nchunk_idx: {r['chunk_idx']}\\nqname: {r['qname']}\\n\")\n","            lines.append(f\"GT(new): {r['new_gt_index']}  pred: {r['pred_index']}  correct: {r['correct']}  invalid: {r['invalid_format']}\")\n","            lines.append(\"\\n### QUESTION (shuffled)\\n\" + json.dumps({\"question\": log.get(\"question\"), \"choices\": log.get(\"choices\")}, ensure_ascii=False, indent=2))\n","            lines.append(\"\\n### PROMPT SENT (exact)\\n\" + (log.get(\"prompt_sent\",\"\") or \"\"))\n","            lines.append(\"\\n### RAW RESPONSE\\n\" + (log.get(\"raw_response\",\"\") or \"\"))\n","            lpath = os.path.join(local_base_dir(), f\"samples/{stage_code}/{cls}/{key}.txt\")\n","            if not os.path.exists(lpath):\n","                write_local_text(lpath, \"\\n\".join(lines))\n","\n","# ====================== Metrics ======================\n","def index_distribution(series: pd.Series, k: int=4) -> Dict[int,float]:\n","    cnt = series.value_counts().reindex(range(k), fill_value=0).sort_index()\n","    tot = int(cnt.sum())\n","    if tot==0: return {i:0.0 for i in range(k)}\n","    share = (cnt / tot).fillna(0.0)\n","    return {int(i): float(share.iloc[i]) for i in range(k)}\n","\n","def summarize_stage(df: pd.DataFrame, qname: str, stage_code: str) -> Dict[str,Any]:\n","    sub = df[(df[\"qname\"]==qname) & (df[\"stage\"]==stage_code)].copy()\n","    provided = len(sub)\n","    valid = int((sub[\"invalid_format\"]==0).sum())\n","    correct_total = int(sub.loc[sub[\"invalid_format\"]==0, \"correct\"].fillna(0).astype(int).sum())\n","    acc = float(correct_total / valid) if valid else None\n","    pred_dist = index_distribution(sub.loc[sub[\"invalid_format\"]==0, \"pred_index\"].dropna().astype(int),4) if valid else {i:0.0 for i in range(4)}\n","    return {\"stage\":stage_code, \"qname\":qname, \"provided\":int(provided), \"answered_valid\":int(valid),\n","            \"correct_total\":int(correct_total), \"accuracy\":acc, \"pred_index_dist\":pred_dist,\n","            \"invalid_format_total\": int((sub[\"invalid_format\"]==1).sum())}\n","\n","# ====================== Main Flow ======================\n","# 0) Run label\n","if RESUME_RUN_LABEL.strip():\n","    RUN_LABEL = RESUME_RUN_LABEL.strip()\n","elif not RUN_LABEL.strip():\n","    RUN_LABEL = make_run_label()\n","\n","ensure_local_dir(local_base_dir())\n","if not exists_any(\"manifest.json\"):\n","    manifest = {\n","        \"run_label\": RUN_LABEL,\n","        \"run_id\": RUN_ID,\n","        \"num_live_requested\": NUM_LIVE,\n","        \"rng_seed_base\": RNG_SEED_BASE,\n","        \"model_name\": MODEL_NAME,\n","        \"temperature\": TEMPERATURE,\n","        \"created_at\": datetime.datetime.now().isoformat(timespec=\"seconds\"),\n","        \"pairs_csv\": PAIRS_CSV_PATH,\n","        \"random_one_if_single\": RANDOM_ONE_IF_SINGLE,\n","        \"exclude_live_ids\": EXCLUDE_LIVE_IDS,\n","    }\n","    write_both_json(\"manifest.json\", manifest)\n","\n","print(f\"RUN_LABEL: {RUN_LABEL}\")\n","print(f\"Local out: {local_base_dir()}\")\n","print(f\"GCS out:   {gcs_base_prefix()}\")\n","print(f\"Pairs CSV: {PAIRS_CSV_PATH}\")\n","\n","# 1) Load pairs & select lives (random if single & not explicit)\n","pairs_df = load_pairs_df()\n","target_lives = select_live_ids(pairs_df, NUM_LIVE)\n","write_both_json(\"selected_live_ids.json\", {\"live_ids\": target_lives})\n","print(\"選択 live_id:\", target_lives)\n","\n","# 2) Build chunk list for target lives\n","sub_pairs = pairs_df[pairs_df[\"vod_id\"].isin(target_lives)].copy()\n","sub_pairs = sub_pairs.sort_values([\"vod_id\",\"chunk_idx\"])\n","\n","# 3) MCQ generation (per chunk, using combined)\n","model = init_vertex_ai(MODEL_NAME)\n","\n","created_mcq = 0\n","paths_full = []\n","pbar = tqdm(total=len(sub_pairs), desc=\"MCQ: 0/chunks\", dynamic_ncols=True)\n","done = 0\n","for row in sub_pairs.itertuples(index=False):\n","    lid = str(row.vod_id); idx = int(row.chunk_idx)\n","    rel_full = q_full_path(lid, idx)\n","    rel_pub  = q_pub_path(lid, idx)\n","    if exists_any(rel_full) and exists_any(rel_pub):\n","        paths_full.append(rel_full)\n","        done += 1; pbar.set_description_str(f\"MCQ: {done}/{len(sub_pairs)}\"); pbar.update(1)\n","        continue\n","    # read combined\n","    try:\n","        combined_text = read_gcs_text(row.combined_path)\n","    except Exception as e:\n","        done += 1; pbar.set_description_str(f\"MCQ: {done}/{len(sub_pairs)}\"); pbar.update(1)\n","        continue\n","    if len((combined_text or \"\").strip()) < MIN_COMBINED_CHARS:\n","        done += 1; pbar.set_description_str(f\"MCQ: {done}/{len(sub_pairs)}\"); pbar.update(1)\n","        continue\n","    mcq = generate_mcq_for_chunk(model, combined_text, save_label=f\"mcq_{lid}_{idx}\")\n","    if isinstance(mcq, dict) and mcq.get(\"questions\") and len(mcq[\"questions\"])==2:\n","        write_both_json(rel_full, mcq)\n","        q1 = mcq[\"questions\"][0]; q2 = mcq[\"questions\"][1]\n","        pub = {\"questions\":[{\"question\":q1[\"question\"],\"choices\":q1[\"choices\"][:4]},\n","                            {\"question\":q2[\"question\"],\"choices\":q2[\"choices\"][:4]}]}\n","        write_both_json(rel_pub, pub)\n","        created_mcq += 1\n","        paths_full.append(rel_full)\n","    done += 1; pbar.set_description_str(f\"MCQ: {done}/{len(sub_pairs)}\"); pbar.update(1)\n","pbar.close()\n","print(f\"MCQ created (new): {created_mcq}\")\n","\n","# 4) Distribution BEFORE shuffle\n","dist_before = gt_distribution_from_full(paths_full)\n","write_both_json(\"metrics_dist_before.json\", dist_before)\n","print(\"\\n=== GT index distribution (BEFORE shuffle) ===\")\n","print(json.dumps(dist_before, ensure_ascii=False, indent=2))\n","\n","# 5) Shuffle choices (stable) & record\n","shuffle_keys = []\n","pbar = tqdm(total=len(paths_full), desc=\"Shuffle: 0/chunks\", dynamic_ncols=True)\n","done = 0\n","for rel_full in paths_full:\n","    base = os.path.basename(rel_full).replace(\".json\",\"\")  # lid_idx\n","    lid, idx = base.split(\"_\", 1)\n","    idx = int(idx)\n","    mcq = read_any_json(rel_full)\n","    if not (isinstance(mcq, dict) and mcq.get(\"questions\") and len(mcq[\"questions\"])==2):\n","        done += 1; pbar.set_description_str(f\"Shuffle: {done}/{len(paths_full)}\"); pbar.update(1)\n","        continue\n","    for qname in (\"Q1\",\"Q2\"):\n","        rec = get_or_make_shuffle_record(lid, idx, qname, mcq)\n","        shuffle_keys.append(rec[\"key\"])\n","    done += 1; pbar.set_description_str(f\"Shuffle: {done}/{len(paths_full)}\"); pbar.update(1)\n","pbar.close()\n","\n","# 6) Distribution AFTER shuffle\n","dist_after = gt_distribution_from_shuffled(shuffle_keys)\n","write_both_json(\"metrics_dist_after.json\", dist_after)\n","print(\"\\n=== GT index distribution (AFTER shuffle) ===\")\n","print(json.dumps(dist_after, ensure_ascii=False, indent=2))\n","\n","# 7) Build answering tasks\n","def build_tasks_from_pairs_and_mcq(sub_pairs: pd.DataFrame) -> List[Dict[str,Any]]:\n","    tasks = []\n","    for row in sub_pairs.itertuples(index=False):\n","        lid = str(row.vod_id); idx = int(row.chunk_idx)\n","        rel_full = q_full_path(lid, idx)\n","        if not exists_any(rel_full):\n","            continue\n","        mcq = read_any_json(rel_full)\n","        if not (isinstance(mcq, dict) and mcq.get(\"questions\") and len(mcq[\"questions\"])==2):\n","            continue\n","        has_chat = isinstance(row.chatonly_path, str) and len(row.chatonly_path) > 0\n","        tasks.append({\n","            \"lid\": lid, \"chunk_idx\": idx,\n","            \"combined_path\": row.combined_path,\n","            \"chat_path\": row.chatonly_path if has_chat else None,\n","            \"has_chat\": bool(has_chat),\n","            \"qname\": \"Q1\",\n","        })\n","        tasks.append({\n","            \"lid\": lid, \"chunk_idx\": idx,\n","            \"combined_path\": row.combined_path,\n","            \"chat_path\": row.chatonly_path if has_chat else None,\n","            \"has_chat\": bool(has_chat),\n","            \"qname\": \"Q2\",\n","        })\n","    return tasks\n","\n","all_tasks = build_tasks_from_pairs_and_mcq(sub_pairs)\n","\n","# 8) Primary stages\n","logs_q1_combined = stage_answer(model, [t for t in all_tasks if t[\"qname\"]==\"Q1\"],\n","                                stage_code=\"Q1_LLM2_combined\",\n","                                source_label=\"配信ログ本文（チャット＋音声書き起こし）\",\n","                                include_body=True)\n","logs_q1_nothing  = stage_answer(model, [t for t in all_tasks if t[\"qname\"]==\"Q1\"],\n","                                stage_code=\"Q1_LLM3_nothing\",\n","                                source_label=\"問題文のみ\",\n","                                include_body=False)\n","\n","logs_q2_combined = stage_answer(model, [t for t in all_tasks if t[\"qname\"]==\"Q2\"],\n","                                stage_code=\"Q2_LLM6_combined\",\n","                                source_label=\"配信ログ本文（チャット＋音声書き起こし）\",\n","                                include_body=True)\n","logs_q2_nothing  = stage_answer(model, [t for t in all_tasks if t[\"qname\"]==\"Q2\"],\n","                                stage_code=\"Q2_LLM7_nothing\",\n","                                source_label=\"問題文のみ\",\n","                                include_body=False)\n","\n","# 9) Subset selection (Q1: LLM2 correct & LLM3 incorrect)\n","df_q1_c = load_stage_logs(\"Q1_LLM2_combined\")\n","df_q1_n = load_stage_logs(\"Q1_LLM3_nothing\")\n","subset_q1 = df_q1_c.merge(df_q1_n, on=[\"key\",\"live_id\",\"chunk_idx\",\"qname\"], suffixes=(\"_llm2\",\"_llm3\"))\n","subset_q1 = subset_q1[(subset_q1[\"correct_llm2\"]==1) & ((subset_q1[\"correct_llm3\"].isna()) | (subset_q1[\"correct_llm3\"]==0))]\n","subset_q1_keys = set(subset_q1[\"key\"].tolist())\n","\n","subset_q1_tasks = [t for t in all_tasks if t[\"qname\"]==\"Q1\" and key_tuple_str(t[\"lid\"], t[\"chunk_idx\"], \"Q1\") in subset_q1_keys]\n","subset_q1_tasks_with_chat = [t for t in subset_q1_tasks if t[\"has_chat\"]]\n","\n","# Q1 extra: chat / nothing\n","logs_q1_chat    = stage_answer(model, subset_q1_tasks_with_chat,\n","                               stage_code=\"Q1_LLM4_chat\",\n","                               source_label=\"チャット本文\",\n","                               include_body=True)\n","logs_q1_nothing2= stage_answer(model, subset_q1_tasks,\n","                               stage_code=\"Q1_LLM5_nothing\",\n","                               source_label=\"問題文のみ\",\n","                               include_body=False)\n","\n","# 10) Subset selection (Q2: LLM6 correct & LLM7 incorrect)\n","df_q2_c = load_stage_logs(\"Q2_LLM6_combined\")\n","df_q2_n = load_stage_logs(\"Q2_LLM7_nothing\")\n","subset_q2 = df_q2_c.merge(df_q2_n, on=[\"key\",\"live_id\",\"chunk_idx\",\"qname\"], suffixes=(\"_llm6\",\"_llm7\"))\n","subset_q2 = subset_q2[(subset_q2[\"correct_llm6\"]==1) & ((subset_q2[\"correct_llm7\"].isna()) | (subset_q2[\"correct_llm7\"]==0))]\n","subset_q2_keys = set(subset_q2[\"key\"].tolist())\n","\n","subset_q2_tasks = [t for t in all_tasks if t[\"qname\"]==\"Q2\" and key_tuple_str(t[\"lid\"], t[\"chunk_idx\"], \"Q2\") in subset_q2_keys]\n","subset_q2_tasks_with_chat = [t for t in subset_q2_tasks if t[\"has_chat\"]]\n","\n","# Q2 extra: chat / nothing\n","logs_q2_chat    = stage_answer(model, subset_q2_tasks_with_chat,\n","                               stage_code=\"Q2_LLM8_chat\",\n","                               source_label=\"チャット本文\",\n","                               include_body=True)\n","logs_q2_nothing2= stage_answer(model, subset_q2_tasks,\n","                               stage_code=\"Q2_LLM9_nothing\",\n","                               source_label=\"問題文のみ\",\n","                               include_body=False)\n","\n","# 11) サンプル（各ステージ：正解2・不正解2をローカル保存）\n","for st in [\"Q1_LLM2_combined\",\"Q1_LLM3_nothing\",\"Q1_LLM4_chat\",\"Q1_LLM5_nothing\",\n","           \"Q2_LLM6_combined\",\"Q2_LLM7_nothing\",\"Q2_LLM8_chat\",\"Q2_LLM9_nothing\"]:\n","    save_stage_samples(st, k_each=2)\n","\n","# 12) Metrics（分布・精度など）\n","stage_codes = [\"Q1_LLM2_combined\",\"Q1_LLM3_nothing\",\"Q1_LLM4_chat\",\"Q1_LLM5_nothing\",\n","               \"Q2_LLM6_combined\",\"Q2_LLM7_nothing\",\"Q2_LLM8_chat\",\"Q2_LLM9_nothing\"]\n","logs_all = []\n","for st in stage_codes:\n","    df = load_stage_logs(st)\n","    if not df.empty:\n","        logs_all.append(df)\n","logs_df = pd.concat(logs_all, ignore_index=True) if logs_all else pd.DataFrame(columns=[\"key\",\"stage\",\"live_id\",\"chunk_idx\",\"qname\",\"new_gt_index\",\"pred_index\",\"invalid_format\",\"correct\"])\n","\n","summaries = {\"Q1\":{}, \"Q2\":{}}\n","for st in [\"Q1_LLM2_combined\",\"Q1_LLM3_nothing\",\"Q1_LLM4_chat\",\"Q1_LLM5_nothing\"]:\n","    summaries[\"Q1\"][st] = summarize_stage(logs_df, \"Q1\", st)\n","for st in [\"Q2_LLM6_combined\",\"Q2_LLM7_nothing\",\"Q2_LLM8_chat\",\"Q2_LLM9_nothing\"]:\n","    summaries[\"Q2\"][st] = summarize_stage(logs_df, \"Q2\", st)\n","\n","subset_sizes = {\n","    \"Q1_total\": len(subset_q1_tasks),\n","    \"Q1_with_chat\": len(subset_q1_tasks_with_chat),\n","    \"Q2_total\": len(subset_q2_tasks),\n","    \"Q2_with_chat\": len(subset_q2_tasks_with_chat),\n","}\n","\n","def gt_distribution_from_files_or_empty() -> Tuple[Dict[str,Dict[int,float]], Dict[str,Dict[int,float]]]:\n","    try:\n","        return (json.loads(read_gcs_text(f\"{gcs_base_prefix()}/metrics_dist_before.json\")),\n","                json.loads(read_gcs_text(f\"{gcs_base_prefix()}/metrics_dist_after.json\")))\n","    except Exception:\n","        return ({}, {})\n","\n","metrics = {\n","    \"run_label\": RUN_LABEL,\n","    \"run_id\": RUN_ID,\n","    \"num_live\": len(target_lives),\n","    \"gt_index_distribution_before\": gt_distribution_from_files_or_empty()[0],\n","    \"gt_index_distribution_after\": gt_distribution_from_files_or_empty()[1],\n","    \"stage_summaries\": summaries,\n","    \"subset_sizes\": subset_sizes,\n","    \"generated_at\": datetime.datetime.now().isoformat(timespec=\"seconds\"),\n","}\n","write_both_json(\"metrics.json\", metrics)\n","\n","# 13) Human-readable print with pred_dist\n","def _fmt_stage_line(s: Dict[str,Any]) -> str:\n","    acc = \"NA\" if s[\"accuracy\"] is None else f\"{s['accuracy']:.3f}\"\n","    return (f\"{s['stage']}: provided={s['provided']} valid={s['answered_valid']} \"\n","            f\"correct={s['correct_total']} acc={acc} pred_dist={s['pred_index_dist']} \"\n","            f\"invalid={s['invalid_format_total']}\")\n","\n","print(\"\\n--- Q1 ---\")\n","for st in [\"Q1_LLM2_combined\",\"Q1_LLM3_nothing\",\"Q1_LLM4_chat\",\"Q1_LLM5_nothing\"]:\n","    print(_fmt_stage_line(summaries[\"Q1\"][st]))\n","\n","print(\"\\n--- Q2 ---\")\n","for st in [\"Q2_LLM6_combined\",\"Q2_LLM7_nothing\",\"Q2_LLM8_chat\",\"Q2_LLM9_nothing\"]:\n","    print(_fmt_stage_line(summaries[\"Q2\"][st]))\n","\n","print(\"\\n=== Conditional subset sizes ===\")\n","print(f\"Q1 subset (LLM2 correct & LLM3 incorrect): total={subset_sizes['Q1_total']}; with_chat={subset_sizes['Q1_with_chat']}\")\n","print(f\"Q2 subset (LLM6 correct & LLM7 incorrect): total={subset_sizes['Q2_total']}; with_chat={subset_sizes['Q2_with_chat']}\")\n","\n","print(f\"\\nAll done. Local outputs: {local_base_dir()}\")\n","print(f\"GCS outputs:          {gcs_base_prefix()}\")\n"]}]}