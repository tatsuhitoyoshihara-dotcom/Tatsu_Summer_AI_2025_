{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOPibIcl47Dq7MLTdGtqpdd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6ZKBOi7Oyw_i"},"outputs":[],"source":["# ============================================================\n","# Reset & Rebuild: Twitch -> 10min Chunks (CHAT+SPEECH / CHAT-only)\n","# - 既存成果物(出力)を削除してから、ゼロから再作成\n","# - 入力(raw/chat, processed/whisper_tiny_csv)は読み込み専用\n","# ============================================================\n","\n","from __future__ import annotations\n","import os, io, re, json, math\n","from typing import List, Dict, Optional, Iterable, Tuple\n","\n","import pandas as pd\n","from tqdm.auto import tqdm\n","from google.cloud import storage\n","import gcsfs\n","\n","# -----------------------\n","# 設定\n","# -----------------------\n","GCS_BUCKET      = \"dena-ai-intern-yoshihara-data\"\n","GCS_ROOT_PREFIX = \"twitch_v2\"\n","RUN_ID          = \"20250910_190657\"     # 失敗した run_id に合わせる\n","CHUNK_SECONDS   = 10 * 60               # 10分\n","\n","# ★ 成果物の保存先（Pocochaと同じ命名）\n","OUT_COMBINED_PREFIX = \"gs://dena-ai-intern-yoshihara-data/yoshi_LLMQA_twitch_comment_speeech_combined\"\n","OUT_CHATONLY_PREFIX = \"gs://dena-ai-intern-yoshihara-data/yoshi_LLMQA_twitch_comment_only\"\n","OUT_EXT             = \".txt\"\n","\n","# （任意）処理対象 VOD を限定する場合は列挙\n","VOD_WHITELIST: Optional[List[str]] = None   # 例: [\"2561964528\"]\n","\n","# 削除を本当に実行するか（True で実行）\n","PURGE_OUTPUTS = True\n","\n","# -----------------------\n","# GCS ユーティリティ\n","# -----------------------\n","gcs_client = storage.Client()\n","bucket = gcs_client.bucket(GCS_BUCKET)\n","fs = gcsfs.GCSFileSystem()\n","\n","def parse_gcs_path(gcs_path: str) -> Tuple[str, str]:\n","    assert gcs_path.startswith(\"gs://\")\n","    rest = gcs_path[5:]\n","    bkt, _, prefix = rest.partition(\"/\")\n","    prefix = prefix.rstrip(\"/\") + (\"/\" if prefix and not prefix.endswith(\"/\") else \"\")\n","    return bkt, prefix\n","\n","def blob_exists(key: str) -> bool:\n","    return bucket.blob(key).exists()\n","\n","def download_bytes(key: str) -> bytes:\n","    bl = bucket.blob(key)\n","    if not bl.exists():\n","        raise FileNotFoundError(f\"not found: gs://{GCS_BUCKET}/{key}\")\n","    return bl.download_as_bytes()\n","\n","def download_csv_df(key: str) -> pd.DataFrame:\n","    data = download_bytes(key)\n","    return pd.read_csv(io.BytesIO(data))\n","\n","def whisper_csv_key(vod_id: str) -> str:\n","    return f\"{GCS_ROOT_PREFIX}/{RUN_ID}/processed/whisper_tiny_csv/{vod_id}.csv\"\n","\n","def chat_json_key(vod_id: str) -> str:\n","    return f\"{GCS_ROOT_PREFIX}/{RUN_ID}/raw/chat/{vod_id}_chat.json\"\n","\n","def list_whisper_csv_vods(run_id: str) -> List[str]:\n","    prefix = f\"{GCS_ROOT_PREFIX}/{run_id}/processed/whisper_tiny_csv/\"\n","    vods = []\n","    for bl in gcs_client.list_blobs(GCS_BUCKET, prefix=prefix):\n","        base = os.path.basename(bl.name)\n","        if base.endswith(\".csv\") and (bl.size or 0) > 0:\n","            vods.append(base[:-4])\n","    return sorted(set(vods))\n","\n","# -----------------------\n","# 時刻・テキスト整形\n","# -----------------------\n","_HMS_RE = re.compile(r\"^(?P<h>\\d{1,2}):(?P<m>\\d{2}):(?P<s>\\d{2})(?:\\.(?P<ms>\\d{1,3}))?$\")\n","\n","def hms_to_seconds(hms: str) -> int:\n","    if not isinstance(hms, str):\n","        return 0\n","    m = _HMS_RE.match(hms.strip())\n","    if not m:\n","        return 0\n","    h = int(m.group(\"h\")); mi = int(m.group(\"m\")); s = int(m.group(\"s\"))\n","    ms = int(m.group(\"ms\") or 0)\n","    return int(h*3600 + mi*60 + s + (ms/1000.0))\n","\n","def to_int_seconds_safe(x) -> int:\n","    try:\n","        v = float(x)\n","        if math.isnan(v):\n","            return 0\n","        return max(0, int(v))\n","    except Exception:\n","        return 0\n","\n","def extract_chat_text(m: Dict) -> str:\n","    \"\"\"Twitchチャット本文抽出（fragments → body/text → top-level text/body/content）\"\"\"\n","    msg = m.get(\"message\")\n","    text = \"\"\n","    if isinstance(msg, dict):\n","        frags = msg.get(\"fragments\")\n","        if isinstance(frags, list):\n","            text = \"\".join(str(f.get(\"text\") or \"\") for f in frags)\n","        else:\n","            text = (msg.get(\"body\") or msg.get(\"text\") or \"\")\n","    elif isinstance(msg, str):\n","        text = msg\n","    if not text:\n","        text = (m.get(\"text\") or m.get(\"body\") or m.get(\"content\") or \"\")\n","        if not text and isinstance(m.get(\"fragments\"), list):\n","            text = \"\".join(str(f.get(\"text\") or \"\") for f in m[\"fragments\"])\n","    return str(text).strip()\n","\n","# -----------------------\n","# ローダ\n","# -----------------------\n","def load_chat_df(vod_id: str) -> pd.DataFrame:\n","    raw = download_bytes(chat_json_key(vod_id))\n","    try:\n","        obj = json.loads(raw.decode(\"utf-8\"))\n","    except Exception:\n","        obj = json.loads(raw.decode(\"utf-8\", errors=\"ignore\"))\n","\n","    if isinstance(obj, dict):\n","        if \"messages\" in obj and isinstance(obj[\"messages\"], list):\n","            messages = obj[\"messages\"]\n","        elif \"data\" in obj and isinstance(obj[\"data\"], list):\n","            messages = obj[\"data\"]\n","        else:\n","            messages = None\n","            for v in obj.values():\n","                if isinstance(v, list):\n","                    messages = v; break\n","            if messages is None:\n","                raise ValueError(\"CHAT JSON のリストが見つかりません\")\n","    elif isinstance(obj, list):\n","        messages = obj\n","    else:\n","        raise ValueError(\"CHAT JSON の形式が不正です\")\n","\n","    rows = []\n","    for i, m in enumerate(messages):\n","        if not isinstance(m, dict):\n","            continue\n","        text = extract_chat_text(m)\n","        if not text:\n","            continue\n","        t_candidates = [m.get(\"offset_seconds\"), m.get(\"offsetSecs\"),\n","                        m.get(\"offset\"), m.get(\"elapsed_seconds\"), m.get(\"t\")]\n","        t_val = None\n","        for cand in t_candidates:\n","            if cand is None:\n","                continue\n","            t_val = to_int_seconds_safe(cand); break\n","        if (t_val is None or t_val == 0):\n","            rel = m.get(\"relative_time\") or m.get(\"time\") or m.get(\"display_time\")\n","            if isinstance(rel, str) and \":\" in rel:\n","                t_val = hms_to_seconds(rel)\n","        if t_val is None:\n","            t_val = 0\n","        rows.append({\"source\":\"CHAT\",\"t\":t_val,\"content\":text,\"orig_idx\":i})\n","\n","    df = pd.DataFrame(rows, columns=[\"source\",\"t\",\"content\",\"orig_idx\"])\n","    if df.empty:\n","        return pd.DataFrame(columns=[\"source\",\"t\",\"content\",\"orig_idx\"])\n","    return df.sort_values([\"t\",\"orig_idx\"], kind=\"mergesort\").reset_index(drop=True)\n","\n","def load_speech_df(vod_id: str) -> pd.DataFrame:\n","    df = download_csv_df(whisper_csv_key(vod_id))\n","    need = {\"timestamp_start\",\"transcription\"}\n","    missing = [c for c in need if c not in df.columns]\n","    if missing:\n","        raise ValueError(f\"Whisper CSV 列不足: {missing}\")\n","    rows = []\n","    for i, r in enumerate(df.itertuples(index=False)):\n","        text = str(getattr(r, \"transcription\", \"\")).strip()\n","        if not text:\n","            continue\n","        t = hms_to_seconds(str(getattr(r, \"timestamp_start\", \"0:00:00\")))\n","        rows.append({\"source\":\"SPEECH\",\"t\":t,\"content\":text,\"orig_idx\":i})\n","    out = pd.DataFrame(rows, columns=[\"source\",\"t\",\"content\",\"orig_idx\"])\n","    if out.empty:\n","        return pd.DataFrame(columns=[\"source\",\"t\",\"content\",\"orig_idx\"])\n","    return out.sort_values([\"t\",\"orig_idx\"], kind=\"mergesort\").reset_index(drop=True)\n","\n","# -----------------------\n","# チャンク & 書き出し\n","# -----------------------\n","def ensure_prefix_no_trailing_slash(prefix: str) -> str:\n","    return prefix[:-1] if prefix.endswith(\"/\") else prefix\n","\n","def out_path(prefix: str, vod_id: str, chunk_idx: int, ext: str = OUT_EXT) -> str:\n","    prefix = ensure_prefix_no_trailing_slash(prefix)\n","    return f\"{prefix}/{vod_id}_{chunk_idx}{ext}\"\n","\n","def build_lines(df: pd.DataFrame) -> List[str]:\n","    if df.empty:\n","        return []\n","    lines = []\n","    for row in df.itertuples(index=False):\n","        text_clean = str(row.content).replace(\"\\n\", \" \").strip()\n","        lines.append(f\"[{row.source}] {text_clean}\")\n","    return lines\n","\n","def iter_chunk_indices(max_t: int, chunk_seconds: int = CHUNK_SECONDS) -> Iterable[int]:\n","    if max_t < 0:\n","        return []\n","    last_chunk = (max_t // chunk_seconds) + 1\n","    return range(1, last_chunk + 1)\n","\n","def export_vod(vod_id: str) -> Tuple[int,int]:\n","    \"\"\"1 VOD を処理して GCS に出力。戻り値: (created, skipped)\"\"\"\n","    created = 0; skipped = 0\n","\n","    if not blob_exists(chat_json_key(vod_id)):\n","        tqdm.write(f\"⚠️ chat なし: {vod_id}\"); return created, skipped\n","    if not blob_exists(whisper_csv_key(vod_id)):\n","        tqdm.write(f\"⚠️ whisper CSV なし: {vod_id}\"); return created, skipped\n","\n","    chat_df   = load_chat_df(vod_id)\n","    speech_df = load_speech_df(vod_id)\n","\n","    chat_df   = chat_df[chat_df[\"content\"].astype(str).str.len() > 0]\n","    speech_df = speech_df[speech_df[\"content\"].astype(str).str.len() > 0]\n","\n","    merged = pd.concat([chat_df, speech_df], ignore_index=True)\n","    source_order = merged[\"source\"].map({\"CHAT\":0, \"SPEECH\":1}).fillna(2).astype(int)\n","    merged = merged.assign(_o=source_order).sort_values([\"t\",\"_o\",\"orig_idx\"], kind=\"mergesort\").drop(columns=[\"_o\"])\n","\n","    if not merged.empty:\n","        merged[\"chunk_idx\"] = (merged[\"t\"] // CHUNK_SECONDS) + 1\n","    if not chat_df.empty:\n","        chat_df = chat_df.sort_values([\"t\",\"orig_idx\"], kind=\"mergesort\").reset_index(drop=True)\n","        chat_df[\"chunk_idx\"] = (chat_df[\"t\"] // CHUNK_SECONDS) + 1\n","\n","    max_t_candidates = []\n","    if not merged.empty:\n","        max_t_candidates.append(int(merged[\"t\"].max()))\n","    if not chat_df.empty:\n","        max_t_candidates.append(int(chat_df[\"t\"].max()))\n","    max_t = max(max_t_candidates) if max_t_candidates else -1\n","    if max_t < 0:\n","        tqdm.write(f\"ℹ️ 有効テキストなし: {vod_id}\")\n","        return created, skipped\n","\n","    for idx in iter_chunk_indices(max_t, CHUNK_SECONDS):\n","        # Combined\n","        out_combined = out_path(OUT_COMBINED_PREFIX, vod_id, idx, OUT_EXT)\n","        if fs.exists(out_combined):\n","            skipped += 1\n","        else:\n","            part = merged[merged[\"chunk_idx\"] == idx]\n","            lines = build_lines(part)\n","            if lines:\n","                with fs.open(out_combined, \"w\", encoding=\"utf-8\") as f:\n","                    txt = \"\\n\".join(lines)\n","                    f.write(txt if txt.endswith(\"\\n\") else txt + \"\\n\")\n","                created += 1\n","\n","        # Chat-only\n","        out_chatonly = out_path(OUT_CHATONLY_PREFIX, vod_id, idx, OUT_EXT)\n","        if fs.exists(out_chatonly):\n","            skipped += 1\n","        else:\n","            part_c = chat_df[chat_df[\"chunk_idx\"] == idx]\n","            lines_c = build_lines(part_c)\n","            if lines_c:\n","                with fs.open(out_chatonly, \"w\", encoding=\"utf-8\") as f:\n","                    txtc = \"\\n\".join(lines_c)\n","                    f.write(txtc if txtc.endswith(\"\\n\") else txtc + \"\\n\")\n","                created += 1\n","\n","    return created, skipped\n","\n","# -----------------------\n","# 成果物の全削除（Purge）\n","# -----------------------\n","def purge_outputs(out_prefix_gs: str, vod_whitelist: Optional[List[str]] = None) -> int:\n","    \"\"\"\n","    指定の 'gs://bucket/prefix' 配下の .txt 成果物を削除。\n","    vod_whitelist があれば '<prefix>/<vod_id>_' の前方一致だけ削除。\n","    戻り値: 削除件数\n","    \"\"\"\n","    bkt, pref = parse_gcs_path(out_prefix_gs)\n","    assert bkt == GCS_BUCKET, f\"想定外のバケット: {bkt}\"\n","\n","    to_delete = []\n","    if vod_whitelist:\n","        for vid in set(vod_whitelist):\n","            subprefix = pref + f\"{vid}_\"\n","            for bl in gcs_client.list_blobs(bkt, prefix=subprefix):\n","                if bl.name.endswith(\".txt\"):\n","                    to_delete.append(bl.name)\n","    else:\n","        for bl in gcs_client.list_blobs(bkt, prefix=pref):\n","            if bl.name.endswith(\".txt\"):\n","                to_delete.append(bl.name)\n","\n","    if not to_delete:\n","        print(f\"🧹 削除対象なし: {out_prefix_gs}\")\n","        return 0\n","\n","    print(f\"🧹 削除対象 {len(to_delete)} 件: {out_prefix_gs}\")\n","    for name in tqdm(to_delete, desc=f\"delete {os.path.basename(out_prefix_gs)}\", unit=\"file\"):\n","        try:\n","            bucket.blob(name).delete()\n","        except Exception as e:\n","            print(f\"  ⚠️ delete失敗: gs://{GCS_BUCKET}/{name} ({e})\")\n","    return len(to_delete)\n","\n","# -----------------------\n","# メイン\n","# -----------------------\n","def main():\n","    # 1) 対象VODの抽出（Whisper CSV あり）\n","    vods = list_whisper_csv_vods(RUN_ID)\n","    if VOD_WHITELIST:\n","        vods = [v for v in vods if v in set(VOD_WHITELIST)]\n","\n","    # chat もあるものだけ\n","    vods_ok = []\n","    for vid in vods:\n","        if blob_exists(chat_json_key(vid)) and blob_exists(whisper_csv_key(vid)):\n","            vods_ok.append(vid)\n","\n","    if not vods_ok:\n","        print(\"処理対象 VOD なし（chat と whisper CSV の両方が必要）\")\n","        return\n","\n","    # 2) 成果物の削除（要求通り「最初からやり直す」ため）\n","    if PURGE_OUTPUTS:\n","        print(\"=== 成果物の全削除を実行します（入力は変更しません）===\")\n","        n1 = purge_outputs(OUT_COMBINED_PREFIX, vods_ok if VOD_WHITELIST else None)\n","        n2 = purge_outputs(OUT_CHATONLY_PREFIX, vods_ok if VOD_WHITELIST else None)\n","        print(f\"削除サマリ: combined={n1}, chatonly={n2}\")\n","\n","    # 3) 再作成（ゼロから）\n","    total_created = 0; total_skipped = 0\n","    pbar = tqdm(vods_ok, desc=\"rebuild VODs\", unit=\"vod\")\n","    for vid in pbar:\n","        c, s = export_vod(vid)\n","        total_created += c; total_skipped += s\n","        pbar.set_postfix_str(f\"created={total_created} skipped={total_skipped}\")\n","\n","    print(\"\\n=== 完了レポート ===\")\n","    print(f\"作成ファイル数: {total_created}\")\n","    print(f\"スキップ数    : {total_skipped}（存在チェックにより）\")\n","    print(f\"出力先 Combined: {OUT_COMBINED_PREFIX}\")\n","    print(f\"出力先 ChatOnly: {OUT_CHATONLY_PREFIX}\")\n","\n","# 実行\n","main()\n"]}]}